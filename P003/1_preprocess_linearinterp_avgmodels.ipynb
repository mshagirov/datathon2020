{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Datasets and Extract Features: linearinterp_avgmodels\n",
    "> Feature engineering notebook\n",
    "\n",
    "Dataset columns (same convention as the lab1):\n",
    "\n",
    "| Col1 | Col2 | Col3 | Col3 | $\\dots$ |\n",
    "|------|------|------|------|---------|\n",
    "| $Y$  |$Y_0$ | $X_1$| $X_2$| $\\dots$ |\n",
    "\n",
    "- $Y$ : labels or target values, in our case $Y(T+18)$\n",
    "- $Y_0$ : present value $Y(T+0)$\n",
    "- $X_1$, $X_2$, $\\dots$ : other features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Baselines**: use only Y(t): energy as features\n",
    "    * [x] Naive windows VS Diff windows (step=1): window_size \\[20, 40, 80\\]\n",
    "* **Wind Speed** Forecast:\n",
    "    * [x] Wind speed forecast X(T+18 ): for each location speed*(sin^2+cos^2) --> 8 additional features\n",
    "    * [x] Wind speed forecast X(T+18 ) for 8 loc-s + diffWindows Y(T) \\[20,40\\]\n",
    "* **Wind Speed Differences**:\n",
    "    * [x] diffWindows Y(T) + Wind speed (T+18, T+0) + naiveWindow X(T)\n",
    "    * [x] diffWindows Y(T) + Wind speed (T+18, T+0) + diffWindows X(T) \\[T+0,T-1,...\\] w=20, w=40\n",
    "* **Wind Speed Differences w/ step**:\n",
    "    * [x] step_diffWindows Y(T) + Wind speed (T+18, T+0) + step_diffWindows X(T) w=20, 40\n",
    "* **Wind Directions**\n",
    "    * [x] Diff-s of Wind speed and **directions** (past), and T+18, T+0 values\n",
    "    * [ ] Seasons (3 month cycles), count months\n",
    "    * [ ] 24 hour clock variable\n",
    "    * [ ] Try adding T+24 (should give next forecast, which is updated 6 hourly)\n",
    "    \n",
    "* Next:\n",
    "    * [ ] sin, cos for each loc-n --> 16 additional features\n",
    "    * [ ] Encoding schemes e.g. positional encoding of Y and X values. \n",
    "    * [ ] Momentum,Force (step=1, 4, 9, 18) \\[Fine tuning\\]\n",
    "    * [ ] Separate Forecast Models\n",
    "    * [ ] Nearest neighbour interpolation dataset\n",
    "    * [ ] what else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[ TRAIN/TEST SPLIT IS DONE AFTER PREPROCESSING FEATURES \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in /P003 folder, changing directory to P003\n"
     ]
    }
   ],
   "source": [
    "#For running in JupyterHub:\n",
    "import os\n",
    "if os.path.basename(os.getcwd())!='P003':\n",
    "    print('Not in /P003 folder, changing directory to P003')\n",
    "    lib_path = os.path.expanduser(os.path.relpath('~/images/codesDIR/datathon2020/P003'))\n",
    "    os.chdir(lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (8,8)\n",
    "matplotlib.rcParams['font.size']= 26 # use for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datautils import windowed_data, windowed_diff_data, windowed_diff_with_step, windowed_momentum_force\n",
    "from src.datautils import locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> We will be using train/test: 95% / 5% split.\n",
      "\n",
      "> Preprocessed data will be saved in `../../../dataDIR/preprocessed_linearinterp_avgmodels`\n",
      "\n",
      "> Lead time is set to T+18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Train% / Test% :\n",
    "TRAIN_PERCENT = 95\n",
    "TEST_PERCENT = 100-TRAIN_PERCENT\n",
    "print(f\"> We will be using train/test: {TRAIN_PERCENT}% / {TEST_PERCENT}% split.\\n\")\n",
    "\n",
    "# Path for Datasets:\n",
    "# all preprocessed data will be saved in `data_path`\n",
    "data_path = os.path.relpath('../../../dataDIR/'+'preprocessed_linearinterp_avgmodels')\n",
    "print(f'> Preprocessed data will be saved in `{data_path}`\\n')\n",
    "\n",
    "# Lead Time :\n",
    "lead_time = 18 # T+18\n",
    "print(f'> Lead time is set to T+{lead_time}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Normalised Dataset (not yet split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "with open('norm_linearinterp_avgmodels.npy', 'rb') as f:\n",
    "    data_norm = np.load(f) # columns (all normalised): Energy, loc1_sin, loc1_cos, ...,loc8_sin, loc8_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data frame contains not normalised data\n",
    "df = pd.read_csv('./ile_de_france_dataset_linearinterp_avgmodels.csv',header=0,index_col=0)\n",
    "df.index =pd.to_datetime(df.index)\n",
    "df['Month'] = df.index.month.values\n",
    "data_months = df['Month'].values.reshape(-1,1)\n",
    "data_season = np.concatenate([np.cos(np.pi*(data_months)/12)**2, np.cos(np.pi*(data_months-3)/12)**2,\n",
    "                              np.cos(np.pi*(data_months-6)/12)**2, np.cos(np.pi*(data_months-9)/12)**2],\n",
    "                            axis=1) # [winter, Spring, Summer, Autumn]\n",
    "\n",
    "data_clock = np.cos(np.pi*df.index.hour.values/23)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy(kWh)</th>\n",
       "      <th>guitrancourt_sin</th>\n",
       "      <th>guitrancourt_cos</th>\n",
       "      <th>lieusaint_sin</th>\n",
       "      <th>lieusaint_cos</th>\n",
       "      <th>lvs-pussay_sin</th>\n",
       "      <th>lvs-pussay_cos</th>\n",
       "      <th>parc-du-gatinais_sin</th>\n",
       "      <th>parc-du-gatinais_cos</th>\n",
       "      <th>arville_sin</th>\n",
       "      <th>arville_cos</th>\n",
       "      <th>boissy-la-riviere_sin</th>\n",
       "      <th>boissy-la-riviere_cos</th>\n",
       "      <th>angerville-1_sin</th>\n",
       "      <th>angerville-1_cos</th>\n",
       "      <th>angerville-2_sin</th>\n",
       "      <th>angerville-2_cos</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-14 14:00:00</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>-2.520584</td>\n",
       "      <td>0.274558</td>\n",
       "      <td>-2.520733</td>\n",
       "      <td>0.514269</td>\n",
       "      <td>-3.017185</td>\n",
       "      <td>0.859413</td>\n",
       "      <td>-2.397853</td>\n",
       "      <td>1.126169</td>\n",
       "      <td>-2.402529</td>\n",
       "      <td>1.086268</td>\n",
       "      <td>-2.877339</td>\n",
       "      <td>0.794478</td>\n",
       "      <td>-2.975787</td>\n",
       "      <td>0.868258</td>\n",
       "      <td>-2.974182</td>\n",
       "      <td>0.867798</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Energy(kWh)  guitrancourt_sin  guitrancourt_cos  \\\n",
       "2020-07-14 14:00:00      10500.0         -2.520584          0.274558   \n",
       "\n",
       "                     lieusaint_sin  lieusaint_cos  lvs-pussay_sin  \\\n",
       "2020-07-14 14:00:00      -2.520733       0.514269       -3.017185   \n",
       "\n",
       "                     lvs-pussay_cos  parc-du-gatinais_sin  \\\n",
       "2020-07-14 14:00:00        0.859413             -2.397853   \n",
       "\n",
       "                     parc-du-gatinais_cos  arville_sin  arville_cos  \\\n",
       "2020-07-14 14:00:00              1.126169    -2.402529     1.086268   \n",
       "\n",
       "                     boissy-la-riviere_sin  boissy-la-riviere_cos  \\\n",
       "2020-07-14 14:00:00              -2.877339               0.794478   \n",
       "\n",
       "                     angerville-1_sin  angerville-1_cos  angerville-2_sin  \\\n",
       "2020-07-14 14:00:00         -2.975787          0.868258         -2.974182   \n",
       "\n",
       "                     angerville-2_cos  Month  \n",
       "2020-07-14 14:00:00          0.867798      7  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index==pd.to_datetime('2020-07-14 14:00:00')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data_clock,data_norm[:,0],'o',alpha=.05,ms=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[10,5])\n",
    "# t = np.arange(1,13)\n",
    "# pl = plt.scatter(df['Month'],df['Energy(kWh)'],s=200,alpha=.2,c=np.arange(0,df.shape[0]))\n",
    "# plt.xticks(t)\n",
    "# fig.colorbar(pl);\n",
    "# plt.title('Energy (kWh) by month');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[18,6])\n",
    "# plt.plot(df['Month'].values/12,lw=3,alpha=.8)\n",
    "# plt.plot(data_season[:,0],lw=3,alpha=.5)\n",
    "# plt.plot(data_season[:,2],lw=3,alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 01/01/2017 - 01/06/2017 : 43MW\n",
    "- 01/06/2017 - 01/12/2017 : 55MW (+ \"Arville\" 12MW)\n",
    "- 01/12/2017 - 01/09/2019 : 70MW (+ \"Boissy-la-Riviere\" 15MW)\n",
    "- 01/09/2019 - now : 89MW (~89.8MW) (+ \"Angerville 1\" 8.8MW, \"Angerville 2\" 11MW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turning off wind forecasts from unopened farms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off signal from not open farms\n",
    "data_normfarm = data_norm\n",
    "data_normfarm[(df.index<pd.to_datetime('2017-06-01 00:00:00')),df.columns.get_loc('arville_sin')]=0\n",
    "data_normfarm[(df.index<pd.to_datetime('2017-06-01 00:00:00')),df.columns.get_loc('arville_cos')]=0\n",
    "\n",
    "data_normfarm[(df.index<pd.to_datetime('2017-12-01 00:00:00')),df.columns.get_loc('boissy-la-riviere_sin')]=0\n",
    "data_normfarm[(df.index<pd.to_datetime('2017-12-01 00:00:00')),df.columns.get_loc('boissy-la-riviere_cos')]=0\n",
    "\n",
    "data_normfarm[(df.index<pd.to_datetime('2019-09-01 00:00:00')),df.columns.get_loc('angerville-1_sin')]=0\n",
    "data_normfarm[(df.index<pd.to_datetime('2019-09-01 00:00:00')),df.columns.get_loc('angerville-1_cos')]=0\n",
    "data_normfarm[(df.index<pd.to_datetime('2019-09-01 00:00:00')),df.columns.get_loc('angerville-2_sin')]=0\n",
    "data_normfarm[(df.index<pd.to_datetime('2019-09-01 00:00:00')),df.columns.get_loc('angerville-2_cos')]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock, Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "data_clock: (30917, 1)\n",
      "Training dataset: (29371, 190)\n",
      "Testing dataset: (1546, 190)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind20_speedclock.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind20_speedclock.npy\n",
      "Training dataset: (29371, 370)\n",
      "Testing dataset: (1546, 370)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind40_speedclock.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind40_speedclock.npy\n",
      "Training dataset: (29371, 730)\n",
      "Testing dataset: (1546, 730)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind80_speedclock.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind80_speedclock.npy\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])\n",
    "\n",
    "# X_clock_diffwind = windowed_diff_data(data_clock, lead_time=lead_time, window_size=window_size)\n",
    "X_clock = data_clock[start_time+lead_time:].reshape(-1,1) \n",
    "print(f'data_clock: {X_clock.shape}')\n",
    "\n",
    "\n",
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "\n",
    "feature_WINDOW_SIZE = [20, 40, 80]\n",
    "\n",
    "for W_size in feature_WINDOW_SIZE:\n",
    "    YXdif_speedclock = [Y_norm_diffwind[:,:(W_size+1)]]\n",
    "    # append X(t+18), X(t+0), X_norm_diffwindows [dir1_sin(T+18),dir1_cos(T+18),...,dir8_sin,dir8_cos(T+18)]\n",
    "    YXdif_speedclock.extend([Xt[:,:(W_size+1)] for Xt in X_norm_diffwindows])\n",
    "    # append seasons\n",
    "    YXdif_speedclock.append(X_clock)\n",
    "    # concatenation\n",
    "    YXdif_speedclock = np.concatenate(YXdif_speedclock, axis=1)\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = YXdif_speedclock.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "    X_train = YXdif_speedclock[:split_index,:]\n",
    "    X_test = YXdif_speedclock[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "\n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_YXdifwind{W_size}_speedclock.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "\n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_YXdifwind{W_size}_speedclock.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41*9+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Seasons, Wind Speed, and/or Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "X_seasons: [(30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])\n",
    "\n",
    "X_seasons_diffwindows = []\n",
    "for l in range(data_season.shape[1]):\n",
    "    X_seasons_diffwindows.append(\n",
    "        windowed_diff_data(data_season[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print(f'X_seasons: {[l.shape for l in X_seasons_diffwindows]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 273)\n",
      "Testing dataset: (1546, 273)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind20_speedseason.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind20_speedseason.npy\n",
      "Training dataset: (29371, 533)\n",
      "Testing dataset: (1546, 533)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind40_speedseason.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind40_speedseason.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "\n",
    "feature_WINDOW_SIZE = [20, 40]\n",
    "\n",
    "for W_size in feature_WINDOW_SIZE:\n",
    "    YXdif_speedseason = [Y_norm_diffwind[:,:(W_size+1)]]\n",
    "    # append X(t+18), X(t+0), X_norm_diffwindows [dir1_sin(T+18),dir1_cos(T+18),...,dir8_sin,dir8_cos(T+18)]\n",
    "    YXdif_speedseason.extend([Xt[:,:(W_size+1)] for Xt in X_norm_diffwindows])\n",
    "    # append seasons\n",
    "    YXdif_speedseason.extend([Xt[:,:(W_size+1)] for Xt in X_seasons_diffwindows])\n",
    "    # concatenation\n",
    "    YXdif_speedseason = np.concatenate(YXdif_speedseason, axis=1)\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = YXdif_speedseason.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "    X_train = YXdif_speedseason[:split_index,:]\n",
    "    X_test = YXdif_speedseason[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "\n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_YXdifwind{W_size}_speedseason.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "\n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_YXdifwind{W_size}_speedseason.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Seasons w/ farm info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "X_seasons: [(30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "Training dataset: (29371, 273)\n",
      "Testing dataset: (1546, 273)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind20_speedseason_farm.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind20_speedseason_farm.npy\n",
      "Training dataset: (29371, 533)\n",
      "Testing dataset: (1546, 533)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind40_speedseason_farm.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind40_speedseason_farm.npy\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_normfarm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_normfarm[:,1::2]**2 + data_normfarm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])\n",
    "\n",
    "X_seasons_diffwindows = []\n",
    "for l in range(data_season.shape[1]):\n",
    "    X_seasons_diffwindows.append(\n",
    "        windowed_diff_data(data_season[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print(f'X_seasons: {[l.shape for l in X_seasons_diffwindows]}')\n",
    "\n",
    "\n",
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "feature_WINDOW_SIZE = [20, 40]\n",
    "\n",
    "for W_size in feature_WINDOW_SIZE:\n",
    "    YXdif_speedseason = [Y_norm_diffwind[:,:(W_size+1)]]\n",
    "    # append X(t+18), X(t+0), X_norm_diffwindows [dir1_sin(T+18),dir1_cos(T+18),...,dir8_sin,dir8_cos(T+18)]\n",
    "    YXdif_speedseason.extend([Xt[:,:(W_size+1)] for Xt in X_norm_diffwindows])\n",
    "    # append seasons\n",
    "    YXdif_speedseason.extend([Xt[:,:(W_size+1)] for Xt in X_seasons_diffwindows])\n",
    "    # concatenation\n",
    "    YXdif_speedseason = np.concatenate(YXdif_speedseason, axis=1)\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = YXdif_speedseason.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "    X_train = YXdif_speedseason[:split_index,:]\n",
    "    X_test = YXdif_speedseason[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "\n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_YXdifwind{W_size}_speedseason_farm.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "\n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_YXdifwind{W_size}_speedseason_farm.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ls $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Direction and Speed differences as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Direction differences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "Training dataset: (29371, 357)\n",
      "Testing dataset: (1546, 357)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind20_dir.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind20_dir.npy\n",
      "Training dataset: (29371, 697)\n",
      "Testing dataset: (1546, 697)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind40_dir.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind40_dir.npy\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1) # energy\n",
    "Xt = data_norm[:,1:] # wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(Xt.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(Xt[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])\n",
    "\n",
    "\n",
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "feature_WINDOW_SIZE = [20, 40]\n",
    "\n",
    "for W_size in feature_WINDOW_SIZE:\n",
    "    YXdifwind_dir = [Y_norm_diffwind[:,:(W_size+1)]]\n",
    "    # append X(t+18), X(t+0), X_norm_diffwindows [dir1_sin(T+18),dir1_cos(T+18),...,dir8_sin,dir8_cos(T+18)]\n",
    "    YXdifwind_dir.extend([Xt[:,:(W_size+1)] for Xt in X_norm_diffwindows])\n",
    "    # concatenation\n",
    "    YXdifwind_dir = np.concatenate(YXdifwind_dir, axis=1)\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = YXdifwind_dir.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "    X_train = YXdifwind_dir[:split_index,:]\n",
    "    X_test = YXdifwind_dir[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "\n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_YXdifwind{W_size}_dir.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "\n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_YXdifwind{W_size}_dir.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Directions w/ Farm info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "Training dataset: (29371, 357)\n",
      "Testing dataset: (1546, 357)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind20_dir_farm.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind20_dir_farm.npy\n",
      "Training dataset: (29371, 697)\n",
      "Testing dataset: (1546, 697)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_YXdifwind40_dir_farm.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_YXdifwind40_dir_farm.npy\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_normfarm[:,0].reshape(-1,1) # energy\n",
    "Xt = data_normfarm[:,1:] # wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(Xt.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(Xt[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])\n",
    "\n",
    "\n",
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "feature_WINDOW_SIZE = [20, 40]\n",
    "\n",
    "for W_size in feature_WINDOW_SIZE:\n",
    "    YXdifwind_dir = [Y_norm_diffwind[:,:(W_size+1)]]\n",
    "    # append X(t+18), X(t+0), X_norm_diffwindows [dir1_sin(T+18),dir1_cos(T+18),...,dir8_sin,dir8_cos(T+18)]\n",
    "    YXdifwind_dir.extend([Xt[:,:(W_size+1)] for Xt in X_norm_diffwindows])\n",
    "    # concatenation\n",
    "    YXdifwind_dir = np.concatenate(YXdifwind_dir, axis=1)\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = YXdifwind_dir.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "    X_train = YXdifwind_dir[:split_index,:]\n",
    "    X_test = YXdifwind_dir[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "\n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_YXdifwind{W_size}_dir_farm.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "\n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_YXdifwind{W_size}_dir_farm.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Only Energy as Features: Y(t)\n",
    "* Try out window sizes\n",
    "* Differences with step sizes etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Revision video: [Session 3: The Prediction Pipeline](https://youtu.be/4W6-48wXXEc?t=1246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of samples in normalized datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Naive Window as Features\n",
    "- Dataset with window width `window_size`; columns:`[Y(T+lead_time), Y(T+0), ...,Y(T-window_size+1)]` \n",
    "\n",
    "write train/test datasets to :\n",
    "- `train_preprocessed_naivewin{}.npy` and\n",
    "- `test_preprocessed_naivewin{}.npy`\n",
    "\n",
    "`naivewin{}` stands for naive windowed data with window width `{}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30977, 21) ; windowsize:20\n",
      "Training dataset: (29428, 21)\n",
      "Testing dataset: (1549, 21)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naivewin20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naivewin20.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30957, 41) ; windowsize:40\n",
      "Training dataset: (29409, 41)\n",
      "Testing dataset: (1548, 41)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naivewin40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naivewin40.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "Training dataset: (29371, 81)\n",
      "Testing dataset: (1546, 81)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naivewin80.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naivewin80.npy\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZES = [20, 40, 80] # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "\n",
    "x_norm = data_norm[:,0] # Y(t) energy\n",
    "\n",
    "for window_size in WINDOW_SIZES:\n",
    "    # index of last elem of window\n",
    "    start_time = window_size-1\n",
    "    # prepare windows : 1st columns Y(T+lead_time)\n",
    "    X_norm_wind = windowed_data(x_norm, lead_time=lead_time, window_size=window_size)\n",
    "    print(f'\\nFull windowed dataset (1st column is target Y(T+{lead_time}): {X_norm_wind.shape}',\n",
    "          f\"; windowsize:{window_size}\")\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = X_norm_wind.shape[0]*TRAIN_PERCENT//100\n",
    "    \n",
    "    X_train = X_norm_wind[:split_index,:]\n",
    "    X_test = X_norm_wind[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "    \n",
    "    # write to files\n",
    "    \n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_naivewin{window_size}.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "    \n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_naivewin{window_size}.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Differences as Features\n",
    "- First column is `Y(T+lead_time)`\n",
    "- 2nd column is `Y(T+0)`, present value\n",
    "- 3rd to END are differences: `[Y(T+0)-Y(T-1), Y(T-1)-Y(T-2), Y(T-2)-Y(T-3), ...]`\n",
    "\n",
    "write training datasets to :\n",
    "- `train_preprocessed_diff{}.npy` and\n",
    "- `test_preprocessed_diff{}.npy`\n",
    "\n",
    "`diff{}` part stands for difference data for differences from `T-window_size+1` to `T+0` (`window_size-1` $\\Delta T$'s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30977, 21) ; windowsize:20\n",
      "Training dataset: (29428, 21)\n",
      "Testing dataset: (1549, 21)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_diff20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_diff20.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30957, 41) ; windowsize:40\n",
      "Training dataset: (29409, 41)\n",
      "Testing dataset: (1548, 41)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_diff40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_diff40.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "Training dataset: (29371, 81)\n",
      "Testing dataset: (1546, 81)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_diff80.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_diff80.npy\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZES = [20, 40, 80] # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "\n",
    "x_norm = data_norm[:,0] # Y(t) energy\n",
    "\n",
    "for window_size in WINDOW_SIZES:\n",
    "    # index of last elem of window\n",
    "    start_time = window_size-1\n",
    "    # prepare windows : 1st columns Y(T+lead_time)\n",
    "    X_norm_wind = windowed_diff_data(x_norm, lead_time=lead_time, window_size=window_size)\n",
    "    print(f'\\nFull windowed dataset (1st column is target Y(T+{lead_time}): {X_norm_wind.shape}',\n",
    "          f\"; windowsize:{window_size}\")\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = X_norm_wind.shape[0]*TRAIN_PERCENT//100\n",
    "    \n",
    "    X_train = X_norm_wind[:split_index,:]\n",
    "    X_test = X_norm_wind[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "    \n",
    "    # write to files\n",
    "    \n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_diff{window_size}.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "    \n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_diff{window_size}.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Wind Forecast Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T-1)...,X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_windows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_windows.append(\n",
    "        windowed_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print('\\nX(t+18),X(T+0),X(T-1)...,X(T-window_size+1):\\n',[l.shape for l in X_norm_windows])\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Wind Speed at T+18\n",
    "- Wind speed forecast X(T+18 ): for each location speed*(sin^2+cos^2) --> 8 additional features\n",
    "- columns `[Y(T+18), Y(T+0), speed1(T+18),speed2(T+18),...,speed8(T+18)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 10)\n",
      "Testing dataset: (1546, 10)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naive_Y18_Y0_X18.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naive_Y18_Y0_X18.npy\n"
     ]
    }
   ],
   "source": [
    "# columns [Y(T+18), Y(T+0), speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18_Y0_X18=[Y_norm_wind[:,:2]]\n",
    "Y18_Y0_X18.extend([Xt[:,0].reshape(-1,1) for Xt in X_norm_windows])\n",
    "\n",
    "Y18_Y0_X18 = np.concatenate(Y18_Y0_X18, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18_Y0_X18.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18_Y0_X18[:split_index,:]\n",
    "X_test = Y18_Y0_X18[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_naive_Y18_Y0_X18.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_naive_Y18_Y0_X18.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Y(t+0), diff(Y(t+0),...,Y(t-w+1)), +speed magnitudes X(t+18,t+0)\n",
    "- columns `[Y(T+18), Y(T+0),Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1), speed1(T+18),speed2(T+18),...,speed8(T+18)]`\n",
    "where `w` is the `window_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Y(t) window_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 29)\n",
      "Testing dataset: (1546, 29)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18_Y0_dYwind20_X18.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18_Y0_dYwind20_X18.npy\n"
     ]
    }
   ],
   "source": [
    "# Y_norm_diffwind\n",
    "# X_norm_windows\n",
    "Y18_Y0_dYwind20_X18=[Y_norm_diffwind[:,:21]]  #Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "# append [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18_Y0_dYwind20_X18.extend([Xt[:,0].reshape(-1,1) for Xt in X_norm_windows])\n",
    "\n",
    "Y18_Y0_dYwind20_X18=np.concatenate(Y18_Y0_dYwind20_X18, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18_Y0_dYwind20_X18.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18_Y0_dYwind20_X18[:split_index,:]\n",
    "X_test = Y18_Y0_dYwind20_X18[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18_Y0_dYwind20_X18.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18_Y0_dYwind20_X18.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Y(t) window_size=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 49)\n",
      "Testing dataset: (1546, 49)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18_Y0_dYwind40_X18.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18_Y0_dYwind40_X18.npy\n"
     ]
    }
   ],
   "source": [
    "# Y_norm_diffwind\n",
    "# X_norm_windows\n",
    "Y18_Y0_dYwind40_X18=[Y_norm_diffwind[:,:41]]  #Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-38)-Y(t-39)\n",
    "\n",
    "# append [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18_Y0_dYwind40_X18.extend([Xt[:,0].reshape(-1,1) for Xt in X_norm_windows])\n",
    "\n",
    "Y18_Y0_dYwind40_X18=np.concatenate(Y18_Y0_dYwind40_X18, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18_Y0_dYwind40_X18.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18_Y0_dYwind40_X18[:split_index,:]\n",
    "X_test = Y18_Y0_dYwind40_X18[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18_Y0_dYwind40_X18.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18_Y0_dYwind40_X18.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Forecasts T+0 and T+18\n",
    "* diffWindows Y(T) + Wind speed (T+18, T+0) + naiveWindow X(T)\n",
    "* diffWindows Y(T) + Wind speed (T+18, T+0) + diffWindows X(T)`[T+0,T-1,...]` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "\n",
      "X(t+18),X(T+0),X(T-1)...,X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\n",
      " [(30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81), (30917, 81)]\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")\n",
    "\n",
    "X_norm_windows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_windows.append(\n",
    "        windowed_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "print('\\nX(t+18),X(T+0),X(T-1)...,X(T-window_size+1):\\n',[l.shape for l in X_norm_windows])\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size)\n",
    "    )\n",
    "\n",
    "print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_diffwindows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X(t+18), X(t+0) and NaiveWindows( X(t) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 189)\n",
      "Testing dataset: (1546, 189)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dYwind20_X18X0Xwind20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dYwind20_X18X0Xwind20.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "Y18Y0dYwind20_X18X0Xwind20 = [Y_norm_diffwind[:,:21]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dYwind20_X18X0Xwind20.extend([Xt[:,:21] for Xt in X_norm_windows])\n",
    "Y18Y0dYwind20_X18X0Xwind20 = np.concatenate(Y18Y0dYwind20_X18X0Xwind20, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dYwind20_X18X0Xwind20.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dYwind20_X18X0Xwind20[:split_index,:]\n",
    "X_test = Y18Y0dYwind20_X18X0Xwind20[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dYwind20_X18X0Xwind20.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dYwind20_X18X0Xwind20.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X(t+18), X(t+0) and DiffWindows( X(t) ) step=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### w=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 189)\n",
      "Testing dataset: (1546, 189)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dYwind20_X18X0dXwind20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dYwind20_X18X0dXwind20.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-18)-Y(t-19)\n",
    "Y18Y0dYwind20_X18X0dXwind20 = [Y_norm_diffwind[:,:21]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dYwind20_X18X0dXwind20.extend([Xt[:,:21] for Xt in X_norm_diffwindows])\n",
    "Y18Y0dYwind20_X18X0dXwind20 = np.concatenate(Y18Y0dYwind20_X18X0dXwind20, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dYwind20_X18X0dXwind20.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dYwind20_X18X0dXwind20[:split_index,:]\n",
    "X_test = Y18Y0dYwind20_X18X0dXwind20[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dYwind20_X18X0dXwind20.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dYwind20_X18X0dXwind20.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ystr = ['y(t+18)','y(t+0)']\n",
    "# Ystr.extend([f\"y(t{'+' if t>-1 else ''}{t})-y(t{t-1})\" for t in range(0,-80+1,-1)])\n",
    "# print(len(Ystr))\n",
    "# Ystr[:41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### w=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 369)\n",
      "Testing dataset: (1546, 369)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dYwind40_X18X0dXwind40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dYwind40_X18X0dXwind40.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-38)-Y(t-39)\n",
    "Y18Y0dYwind40_X18X0dXwind40 = [Y_norm_diffwind[:,:41]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dYwind40_X18X0dXwind40.extend([Xt[:,:41] for Xt in X_norm_diffwindows])\n",
    "Y18Y0dYwind40_X18X0dXwind40 = np.concatenate(Y18Y0dYwind40_X18X0dXwind40, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dYwind40_X18X0dXwind40.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dYwind40_X18X0dXwind40[:split_index,:]\n",
    "X_test = Y18Y0dYwind40_X18X0dXwind40[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dYwind40_X18X0dXwind40.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dYwind40_X18X0dXwind40.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Time Differences With Step Size\n",
    "- Differences with step size `[Y(T+0)-Y(T-h),...]` where h is a step size\n",
    "- try h : 4, 9, and 18\n",
    "- window size w: 20,40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Difference step size h=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff w/ step windowed dataset (1st column is target Y(T+18): (30917, 78) ; windowsize:80; step size (h):4\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-4),...,X(T-(window_size-1-4))-X(T-window_size+1):\n",
      " [(30917, 78), (30917, 78), (30917, 78), (30917, 78), (30917, 78), (30917, 78), (30917, 78), (30917, 78)]\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "h = 4 # step size for differences\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "# X_norm_wind = windowed_diff_with_step(x_norm, lead_time=lead_time, window_size=window_size,h=lead_time)\n",
    "Y_norm_stepdiffwind = windowed_diff_with_step(Yt, lead_time=lead_time, window_size=window_size, h = h)\n",
    "print(f'\\nFull Diff w/ step windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_stepdiffwind.shape}',\n",
    "      f\"; windowsize:{window_size}; step size (h):{h}\")\n",
    "\n",
    "X_norm_stepdiffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_stepdiffwindows.append(\n",
    "        windowed_diff_with_step(wind_speeds[:,l], lead_time=lead_time, window_size=window_size, h = h)\n",
    "    )\n",
    "\n",
    "print(f'\\nX(t+18),X(T+0),X(T+0)-X(T-{h}),...,X(T-(window_size-1-{h}))-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_stepdiffwindows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ystr = ['y(t+18)','y(t+0)']\n",
    "# Ystr.extend([f\"y(t{'+' if t>-1 else ''}{t})-y(t{t-h*1})\" for t in range(0,-80+1,-1)])\n",
    "# print(len(Ystr))\n",
    "# Ystr[:41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 162)\n",
      "Testing dataset: (1546, 162)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh4Ywind20_X18X0dh4Xwind20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh4Ywind20_X18X0dh4Xwind20.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "Y18Y0dh4Ywind20_X18X0dh4Xwind20 = [Y_norm_stepdiffwind[:,:18]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh4Ywind20_X18X0dh4Xwind20.extend([Xt[:,:18] for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh4Ywind20_X18X0dh4Xwind20 = np.concatenate(Y18Y0dh4Ywind20_X18X0dh4Xwind20, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh4Ywind20_X18X0dh4Xwind20.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh4Ywind20_X18X0dh4Xwind20[:split_index,:]\n",
    "X_test = Y18Y0dh4Ywind20_X18X0dh4Xwind20[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh4Ywind20_X18X0dh4Xwind20.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh4Ywind20_X18X0dh4Xwind20.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 342)\n",
      "Testing dataset: (1546, 342)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh4Ywind40_X18X0dh4Xwind40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh4Ywind40_X18X0dh4Xwind40.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "Y18Y0dh4Ywind40_X18X0dh4Xwind40 = [Y_norm_stepdiffwind[:,:38]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh4Ywind40_X18X0dh4Xwind40.extend([Xt[:,:38] for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh4Ywind40_X18X0dh4Xwind40 = np.concatenate(Y18Y0dh4Ywind40_X18X0dh4Xwind40, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh4Ywind40_X18X0dh4Xwind40.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh4Ywind40_X18X0dh4Xwind40[:split_index,:]\n",
    "X_test = Y18Y0dh4Ywind40_X18X0dh4Xwind40[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh4Ywind40_X18X0dh4Xwind40.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh4Ywind40_X18X0dh4Xwind40.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Difference step size h=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff w/ step windowed dataset (1st column is target Y(T+18): (30917, 73) ; windowsize:80; step size (h):9\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-9),...,X(T-(window_size-1-9))-X(T-window_size+1):\n",
      " [(30917, 73), (30917, 73), (30917, 73), (30917, 73), (30917, 73), (30917, 73), (30917, 73), (30917, 73)]\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "h = 9 # step size for differences\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "# X_norm_wind = windowed_diff_with_step(x_norm, lead_time=lead_time, window_size=window_size,h=lead_time)\n",
    "Y_norm_stepdiffwind = windowed_diff_with_step(Yt, lead_time=lead_time, window_size=window_size, h = h)\n",
    "print(f'\\nFull Diff w/ step windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_stepdiffwind.shape}',\n",
    "      f\"; windowsize:{window_size}; step size (h):{h}\")\n",
    "\n",
    "X_norm_stepdiffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_stepdiffwindows.append(\n",
    "        windowed_diff_with_step(wind_speeds[:,l], lead_time=lead_time, window_size=window_size, h = h)\n",
    "    )\n",
    "\n",
    "print(f'\\nX(t+18),X(T+0),X(T+0)-X(T-{h}),...,X(T-(window_size-1-{h}))-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_stepdiffwindows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 117)\n",
      "Testing dataset: (1546, 117)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh9Ywind20_X18X0dh9Xwind20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh9Ywind20_X18X0dh9Xwind20.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "Y18Y0dh9Ywind20_X18X0dh9Xwind20 = [Y_norm_stepdiffwind[:,:13]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh9Ywind20_X18X0dh9Xwind20.extend([Xt[:,:13] for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh9Ywind20_X18X0dh9Xwind20 = np.concatenate(Y18Y0dh9Ywind20_X18X0dh9Xwind20, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh9Ywind20_X18X0dh9Xwind20.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh9Ywind20_X18X0dh9Xwind20[:split_index,:]\n",
    "X_test = Y18Y0dh9Ywind20_X18X0dh9Xwind20[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh9Ywind20_X18X0dh9Xwind20.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh9Ywind20_X18X0dh9Xwind20.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 297)\n",
      "Testing dataset: (1546, 297)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh9Ywind40_X18X0dh9Xwind40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh9Ywind40_X18X0dh9Xwind40.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "# last_index = 2+ w-h : where h is [1, or 4, or 9, or 18]\n",
    "Y18Y0dh9Ywind40_X18X0dh9Xwind40 = [Y_norm_stepdiffwind[:,:33]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh9Ywind40_X18X0dh9Xwind40.extend([Xt[:,:33] for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh9Ywind40_X18X0dh9Xwind40 = np.concatenate(Y18Y0dh9Ywind40_X18X0dh9Xwind40, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh9Ywind40_X18X0dh9Xwind40.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh9Ywind40_X18X0dh9Xwind40[:split_index,:]\n",
    "X_test = Y18Y0dh9Ywind40_X18X0dh9Xwind40[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh9Ywind40_X18X0dh9Xwind40.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh9Ywind40_X18X0dh9Xwind40.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Difference step size h=18 (lead_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Diff w/ step windowed dataset (1st column is target Y(T+18): (30917, 64) ; windowsize:80; step size (h):18\n",
      "\n",
      "X(t+18),X(T+0),X(T+0)-X(T-18),...,X(T-(window_size-1-18))-X(T-window_size+1):\n",
      " [(30917, 64), (30917, 64), (30917, 64), (30917, 64), (30917, 64), (30917, 64), (30917, 64), (30917, 64)]\n"
     ]
    }
   ],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "wind_speeds = np.sqrt(data_norm[:,1::2]**2 + data_norm[:,2::2]**2) # wind speed from wind vectors\n",
    "\n",
    "# window size\n",
    "window_size = 80 # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "h = 18 # step size for differences\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "# X_norm_wind = windowed_diff_with_step(x_norm, lead_time=lead_time, window_size=window_size,h=lead_time)\n",
    "Y_norm_stepdiffwind = windowed_diff_with_step(Yt, lead_time=lead_time, window_size=window_size, h = h)\n",
    "print(f'\\nFull Diff w/ step windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_stepdiffwind.shape}',\n",
    "      f\"; windowsize:{window_size}; step size (h):{h}\")\n",
    "\n",
    "X_norm_stepdiffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_stepdiffwindows.append(\n",
    "        windowed_diff_with_step(wind_speeds[:,l], lead_time=lead_time, window_size=window_size, h = h)\n",
    "    )\n",
    "\n",
    "print(f'\\nX(t+18),X(T+0),X(T+0)-X(T-{h}),...,X(T-(window_size-1-{h}))-X(T-window_size+1):\\n',\n",
    "      [l.shape for l in X_norm_stepdiffwindows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 36)\n",
      "Testing dataset: (1546, 36)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh18Ywind20_X18X0dh18Xwind20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh18Ywind20_X18X0dh18Xwind20.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "# last_index = 2+ w-h : where h is [1, or 4, or 9, or 18]\n",
    "Y18Y0dh18Ywind20_X18X0dh18Xwind20 = [Y_norm_stepdiffwind[:,:4]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh18Ywind20_X18X0dh18Xwind20.extend([Xt[:,:4] for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh18Ywind20_X18X0dh18Xwind20 = np.concatenate(Y18Y0dh18Ywind20_X18X0dh18Xwind20, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh18Ywind20_X18X0dh18Xwind20.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh18Ywind20_X18X0dh18Xwind20[:split_index,:]\n",
    "X_test = Y18Y0dh18Ywind20_X18X0dh18Xwind20[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh18Ywind20_X18X0dh18Xwind20.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh18Ywind20_X18X0dh18Xwind20.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 216)\n",
      "Testing dataset: (1546, 216)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh18Ywind40_X18X0dh18Xwind40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh18Ywind40_X18X0dh18Xwind40.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "# last_index = 2+ w-h : where h is [1, or 4, or 9, or 18]\n",
    "Y18Y0dh18Ywind40_X18X0dh18Xwind40 = [Y_norm_stepdiffwind[:,:24]]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh18Ywind40_X18X0dh18Xwind40.extend([Xt[:,:24] for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh18Ywind40_X18X0dh18Xwind40 = np.concatenate(Y18Y0dh18Ywind40_X18X0dh18Xwind40, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh18Ywind40_X18X0dh18Xwind40.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh18Ywind40_X18X0dh18Xwind40[:split_index,:]\n",
    "X_test = Y18Y0dh18Ywind40_X18X0dh18Xwind40[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh18Ywind40_X18X0dh18Xwind40.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh18Ywind40_X18X0dh18Xwind40.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### w=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30917, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_norm_stepdiffwind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (29371, 576)\n",
      "Testing dataset: (1546, 576)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_Y18Y0dh18Ywind80_X18X0dh18Xwind80.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_Y18Y0dh18Ywind80_X18X0dh18Xwind80.npy\n"
     ]
    }
   ],
   "source": [
    "#Y18,Y0, Y(t+0)-Y(t-1),..., Y(t-w+2)-Y(t-w+1) [w: window_size]\n",
    "# last_index = 2+ w-h : where h is [1, or 4, or 9, or 18]\n",
    "Y18Y0dh18Ywind80_X18X0dh18Xwind80 = [Y_norm_stepdiffwind]\n",
    "\n",
    "# append X(t+18), X(t+0), Xwind20s [speed1(T+18),speed2(T+18),...,speed8(T+18)]\n",
    "Y18Y0dh18Ywind80_X18X0dh18Xwind80.extend([Xt for Xt in X_norm_stepdiffwindows])\n",
    "Y18Y0dh18Ywind80_X18X0dh18Xwind80 = np.concatenate(Y18Y0dh18Ywind80_X18X0dh18Xwind80, axis=1)\n",
    "\n",
    "# split train/test\n",
    "split_index = Y18Y0dh18Ywind80_X18X0dh18Xwind80.shape[0]*TRAIN_PERCENT//100\n",
    "\n",
    "X_train = Y18Y0dh18Ywind80_X18X0dh18Xwind80[:split_index,:]\n",
    "X_test = Y18Y0dh18Ywind80_X18X0dh18Xwind80[split_index:,:]\n",
    "print('Training dataset:',X_train.shape)\n",
    "print('Testing dataset:',X_test.shape)\n",
    "\n",
    "# training data\n",
    "train_file_name = os.path.join(data_path,f'train_preprocessed_Y18Y0dh18Ywind80_X18X0dh18Xwind80.npy')\n",
    "with open(train_file_name, 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "print(f'Saved : {train_file_name}')\n",
    "\n",
    "# testing data\n",
    "test_file_name = os.path.join(data_path,f'test_preprocessed_Y18Y0dh18Ywind80_X18X0dh18Xwind80.npy')\n",
    "with open(test_file_name, 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_norm_wind = windowed_diff_with_step(x_norm, lead_time=lead_time, window_size=window_size,h=lead_time)\n",
    "\n",
    "# split_index = X_norm_wind.shape[0]*70//100\n",
    "# X_train = X_norm_wind[:split_index,:]\n",
    "# X_test = X_norm_wind[split_index:,:]\n",
    "# print(f'Full windowed dataset: {X_norm_wind.shape}')\n",
    "# print(f'Training dataset (1st column is target Y(T+{lead_time})):',X_train.shape,f\"\\nwindowsize:{window_size}\")\n",
    "# print(f'Testing dataset (1st column is target Y(T+{lead_time})):',X_test.shape,f\"\\nwindowsize:{window_size}\")\n",
    "\n",
    "# # Training data\n",
    "# with open(f'train_preprocessed_stepdiff{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_train)\n",
    "# # Testing data\n",
    "# with open(f'test_preprocessed_stepdiff{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Force and Momentum with Step Size\n",
    "Momentum = Difference of Differences\n",
    "\n",
    "Force = Difference of Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_norm_wind = windowed_momentum_force(x_norm,lead_time=lead_time,window_size=window_size,h=lead_time)\n",
    "\n",
    "# split_index = X_norm_wind.shape[0]*70//100\n",
    "# X_train = X_norm_wind[:split_index,:]\n",
    "# X_test = X_norm_wind[split_index:,:]\n",
    "# print(f'Full windowed dataset: {X_norm_wind.shape}')\n",
    "# print(f'Training dataset (1st column is target Y(T+{lead_time})):',X_train.shape,f\"\\nwindowsize:{window_size}\")\n",
    "# print(f'Testing dataset (1st column is target Y(T+{lead_time})):',X_test.shape,f\"\\nwindowsize:{window_size}\")\n",
    "\n",
    "# # Training data\n",
    "# with open(f'train_preprocessed_mntfrcwin{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_train)\n",
    "# # Testing data\n",
    "# with open(f'test_preprocessed_mntfrcwin{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
