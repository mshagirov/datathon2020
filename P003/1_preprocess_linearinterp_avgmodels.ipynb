{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Datasets and Extract Features: linearinterp_avgmodels\n",
    "> Feature engineering notebook\n",
    "\n",
    "Dataset columns (same convention as the lab1):\n",
    "\n",
    "| Col1 | Col2 | Col3 | Col3 | $\\dots$ |\n",
    "|------|------|------|------|---------|\n",
    "| $Y$  |$Y_0$ | $X_1$| $X_2$| $\\dots$ |\n",
    "\n",
    "- $Y$ : labels or target values, in our case $X(T+18)$\n",
    "- $Y_0$ : present value $X(T+0)$\n",
    "- $X_1$, $X_2$, $\\dots$ : other features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Baselines: use only Y(t): energy as features\n",
    "    * [x] Naive windows VS Diff windows (step=1): window_size \\[20, 40, 80\\]\n",
    "* Add more features:\n",
    "    * [ ] Wind speed current (T+0 ): for each location speed*(sin^2+cos^2) --> 8 additional features\n",
    "    * [ ] Wind speed forecast (T+18)\n",
    "    * [ ] Wind speed (T+18, T+0, T-1,...)\n",
    "    * [ ] Wind speed (T+18, T+0, diff\\[T+0,T-1,...\\] )\n",
    "    * [ ] Wind speed + direction (T+0 and past): sin, cos for each loc-n --> 16 additional features\n",
    "    * [ ] Diff windows + Momentum,Force (step=1, 4, 9, 18) \\[Fine tuning\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[ TRAIN/TEST SPLIT IS DONE AFTER PREPROCESSING FEATURES \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in /P003 folder, changing directory to P003\n"
     ]
    }
   ],
   "source": [
    "#For running in JupyterHub:\n",
    "import os\n",
    "if os.path.basename(os.getcwd())!='P003':\n",
    "    print('Not in /P003 folder, changing directory to P003')\n",
    "    lib_path = os.path.expanduser(os.path.relpath('~/images/codesDIR/datathon2020/P003'))\n",
    "    os.chdir(lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,8)\n",
    "# matplotlib.rcParams['font.size']= 22 # use for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datautils import windowed_data, windowed_diff_data, windowed_diff_with_step, windowed_momentum_force\n",
    "# or\n",
    "# from datautils import windowed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> We will be using train/test: 95% / 5% split.\n",
      "\n",
      "> Preprocessed data will be saved in `../../../dataDIR/preprocessed_linearinterp_avgmodels`\n",
      "\n",
      "> Lead time is set to T+18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Train% / Test% :\n",
    "TRAIN_PERCENT = 95\n",
    "TEST_PERCENT = 100-TRAIN_PERCENT\n",
    "print(f\"> We will be using train/test: {TRAIN_PERCENT}% / {TEST_PERCENT}% split.\\n\")\n",
    "\n",
    "# Path for Datasets:\n",
    "# all preprocessed data will be saved in `data_path`\n",
    "data_path = os.path.relpath('../../../dataDIR/'+'preprocessed_linearinterp_avgmodels')\n",
    "print(f'> Preprocessed data will be saved in `{data_path}`\\n')\n",
    "\n",
    "# Lead Time :\n",
    "lead_time = 18 # T+18\n",
    "print(f'> Lead time is set to T+{lead_time}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Normalised Dataset (not yet split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "with open('norm_linearinterp_avgmodels.npy', 'rb') as f:\n",
    "    data_norm = np.load(f) # columns (all normalised): Energy, loc1_sin, loc1_cos, ...,loc8_sin, loc8_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data_norm[lead_time:,0],'-',label=f'T+{lead_time}',alpha=.5)\n",
    "# plt.plot(data_norm[:-lead_time,0],'-',label=f'T+0',alpha=.3)\n",
    "# plt.axis([9000,10000,-.5,2])\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Only Energy as Features: Y(t)\n",
    "* Try out window sizes\n",
    "* Differences with step sizes etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Revision video: [Session 3: The Prediction Pipeline](https://youtu.be/4W6-48wXXEc?t=1246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of samples in normalized datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Naive Window as Features\n",
    "- Dataset with window width `window_size`; columns:`[Y(T+lead_time), Y(T+0), ...,Y(T-window_size+1)]` \n",
    "\n",
    "write train/test datasets to :\n",
    "- `train_preprocessed_naivewin{}.npy` and\n",
    "- `test_preprocessed_naivewin{}.npy`\n",
    "\n",
    "`naivewin{}` stands for naive windowed data with window width `{}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30977, 21) ; windowsize:20\n",
      "Training dataset: (29428, 21)\n",
      "Testing dataset: (1549, 21)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naivewin20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naivewin20.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30957, 41) ; windowsize:40\n",
      "Training dataset: (29409, 41)\n",
      "Testing dataset: (1548, 41)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naivewin40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naivewin40.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "Training dataset: (29371, 81)\n",
      "Testing dataset: (1546, 81)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_naivewin80.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_naivewin80.npy\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZES = [20, 40, 80] # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "\n",
    "x_norm = data_norm[:,0] # Y(t) energy\n",
    "\n",
    "for window_size in WINDOW_SIZES:\n",
    "    # index of last elem of window\n",
    "    start_time = window_size-1\n",
    "    # prepare windows : 1st columns Y(T+lead_time)\n",
    "    X_norm_wind = windowed_data(x_norm, lead_time=lead_time, window_size=window_size)\n",
    "    print(f'\\nFull windowed dataset (1st column is target Y(T+{lead_time}): {X_norm_wind.shape}',\n",
    "          f\"; windowsize:{window_size}\")\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = X_norm_wind.shape[0]*TRAIN_PERCENT//100\n",
    "    \n",
    "    X_train = X_norm_wind[:split_index,:]\n",
    "    X_test = X_norm_wind[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "    \n",
    "    # write to files\n",
    "    \n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_naivewin{window_size}.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "    \n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_naivewin{window_size}.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Differences as Features\n",
    "- First column is `Y(T+lead_time)`\n",
    "- 2nd column is `Y(T+0)`, present value\n",
    "- 3rd to END are differences: `[Y(T+0)-Y(T-1), Y(T-1)-Y(T-2), Y(T-2)-Y(T-3), ...]`\n",
    "\n",
    "write training datasets to :\n",
    "- `train_preprocessed_diff{}.npy` and\n",
    "- `test_preprocessed_diff{}.npy`\n",
    "\n",
    "`diff{}` part stands for difference data for differences from `T-window_size+1` to `T+0` (`window_size-1` $\\Delta T$'s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30977, 21) ; windowsize:20\n",
      "Training dataset: (29428, 21)\n",
      "Testing dataset: (1549, 21)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_diff20.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_diff20.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30957, 41) ; windowsize:40\n",
      "Training dataset: (29409, 41)\n",
      "Testing dataset: (1548, 41)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_diff40.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_diff40.npy\n",
      "\n",
      "Full windowed dataset (1st column is target Y(T+18): (30917, 81) ; windowsize:80\n",
      "Training dataset: (29371, 81)\n",
      "Testing dataset: (1546, 81)\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/train_preprocessed_diff80.npy\n",
      "Saved : ../../../dataDIR/preprocessed_linearinterp_avgmodels/test_preprocessed_diff80.npy\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZES = [20, 40, 80] # Y(T+0) and \"window_size-1\" previous points, T-1,T-2,...,T-window_size+1\n",
    "\n",
    "x_norm = data_norm[:,0] # Y(t) energy\n",
    "\n",
    "for window_size in WINDOW_SIZES:\n",
    "    # index of last elem of window\n",
    "    start_time = window_size-1\n",
    "    # prepare windows : 1st columns Y(T+lead_time)\n",
    "    X_norm_wind = windowed_diff_data(x_norm, lead_time=lead_time, window_size=window_size)\n",
    "    print(f'\\nFull windowed dataset (1st column is target Y(T+{lead_time}): {X_norm_wind.shape}',\n",
    "          f\"; windowsize:{window_size}\")\n",
    "    \n",
    "    # split train/test\n",
    "    split_index = X_norm_wind.shape[0]*TRAIN_PERCENT//100\n",
    "    \n",
    "    X_train = X_norm_wind[:split_index,:]\n",
    "    X_test = X_norm_wind[split_index:,:]\n",
    "    print('Training dataset:',X_train.shape)\n",
    "    print('Testing dataset:',X_test.shape)\n",
    "    \n",
    "    # write to files\n",
    "    \n",
    "    # training data\n",
    "    train_file_name = os.path.join(data_path,f'train_preprocessed_diff{window_size}.npy')\n",
    "    with open(train_file_name, 'wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    print(f'Saved : {train_file_name}')\n",
    "    \n",
    "    # testing data\n",
    "    test_file_name = os.path.join(data_path,f'test_preprocessed_diff{window_size}.npy')\n",
    "    with open(test_file_name, 'wb') as f:\n",
    "        np.save(f,X_test)\n",
    "    print(f'Saved : {test_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Time Differences With Step Size\n",
    "- Differences with step size `[Y(T+0)-Y(T-h),...]` where h is a step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_norm_wind = windowed_diff_with_step(x_norm, lead_time=lead_time, window_size=window_size,h=lead_time)\n",
    "\n",
    "# split_index = X_norm_wind.shape[0]*70//100\n",
    "# X_train = X_norm_wind[:split_index,:]\n",
    "# X_test = X_norm_wind[split_index:,:]\n",
    "# print(f'Full windowed dataset: {X_norm_wind.shape}')\n",
    "# print(f'Training dataset (1st column is target Y(T+{lead_time})):',X_train.shape,f\"\\nwindowsize:{window_size}\")\n",
    "# print(f'Testing dataset (1st column is target Y(T+{lead_time})):',X_test.shape,f\"\\nwindowsize:{window_size}\")\n",
    "\n",
    "# # Training data\n",
    "# with open(f'train_preprocessed_stepdiff{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_train)\n",
    "# # Testing data\n",
    "# with open(f'test_preprocessed_stepdiff{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Force and Momentum with Step Size\n",
    "Momentum = Difference of Differences\n",
    "\n",
    "Force = Difference of Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_norm_wind = windowed_momentum_force(x_norm,lead_time=lead_time,window_size=window_size,h=lead_time)\n",
    "\n",
    "# split_index = X_norm_wind.shape[0]*70//100\n",
    "# X_train = X_norm_wind[:split_index,:]\n",
    "# X_test = X_norm_wind[split_index:,:]\n",
    "# print(f'Full windowed dataset: {X_norm_wind.shape}')\n",
    "# print(f'Training dataset (1st column is target Y(T+{lead_time})):',X_train.shape,f\"\\nwindowsize:{window_size}\")\n",
    "# print(f'Testing dataset (1st column is target Y(T+{lead_time})):',X_test.shape,f\"\\nwindowsize:{window_size}\")\n",
    "\n",
    "# # Training data\n",
    "# with open(f'train_preprocessed_mntfrcwin{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_train)\n",
    "# # Testing data\n",
    "# with open(f'test_preprocessed_mntfrcwin{window_size}.npy', 'wb') as f:\n",
    "#     np.save(f,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Wind Forecast Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
