{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Deployment\n",
    "> run this notebook during deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To check time offset correction use [https://www.utctime.net](https://www.utctime.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Data from the RTE website collected from 0300 - 0400 Z is averaged and attributed to the time 0300Z. So when you submit a forecast between 0350-0410 Z , it is really meant for a T+0 = 0300Z. Finally, 0300Z + 18 hours = 2100Z as given in the response.\n",
    "\n",
    "USE `Energy[t-1, t-2,...]`, and `Forecast[t+17]` , i.e. `Energy[t-1]` is current reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "our password is` 961993551 `\n",
    "```python\n",
    "Y_t18_prediction = 3500\n",
    "url_to_submit = f'http://3.1.52.222/submit/pred?pwd=961993551&value={Y_t18_prediction}'\n",
    "\n",
    "with urllib.request.urlopen(url_to_submit) as response:\n",
    "   html_valid = response.read()\n",
    "```\n",
    "then convert to pyhton str\n",
    "```python\n",
    "str(html_valid.decode())\n",
    "```\n",
    "if valid submission, we will receive:\n",
    "```\n",
    "> 'Submitted \\nReceived: 20-Jul-2020 04:02:50 UTC \\nFor     : 20-Jul-2020 21:00:00 UTC \\nValue   : 3500 \\n'\n",
    "```\n",
    "and for wrong timing/passwords:\n",
    "```\n",
    "if password is wrong:\n",
    "> 'Password invalid \\n'\n",
    "if submission is too early or late:\n",
    "> 'Submission time closed \\n'\n",
    "```\n",
    "\n",
    "an example for wrong submission code\n",
    "```python\n",
    "html=b''\n",
    "try:\n",
    "    with urllib.request.urlopen('http://3.1.52.222/submit/pred?pwd=961993551&value=3500') as response:\n",
    "        html = response.read()\n",
    "except urllib.request.HTTPError:\n",
    "    html = b'server down'\n",
    "\n",
    "print(html.decode())\n",
    "```\n",
    "\n",
    "`> server down`<br>\n",
    "or<br>\n",
    "```python\n",
    "html.decode().split('\\n')\n",
    "```\n",
    "`> ['Password invalid ', '']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Available device: cuda\n",
      "Loading best_models/20Jul2020_1155_ver2.pkl\n",
      "Loading best_models/20Jul2020_1155_ver1.pkl\n",
      "Loading best_models/20Jul2020_1155_ver5.pkl\n",
      "Loading best_models/20Jul2020_1155_ver3.pkl\n",
      "Loading best_models/20Jul2020_1155_ver4.pkl\n"
     ]
    }
   ],
   "source": [
    "# # Set to FALSE when deploying!!! # #\n",
    "TESTING = False\n",
    "\n",
    "\n",
    "# Just in case\n",
    "deployment_end_time  = pd.to_datetime('2020-12-29 10:00:00')\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob, pickle\n",
    "import urllib.request\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "#     device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Available device: {device}')\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "import time, datetime\n",
    "\n",
    "#For running in JupyterHub:\n",
    "if os.path.basename(os.getcwd())!='P003':\n",
    "    print('Not in /P003 folder, changing directory to P003')\n",
    "    lib_path = os.path.expanduser(os.path.relpath('~/images/codesDIR/datathon2020/P003'))\n",
    "    os.chdir(lib_path)\n",
    "\n",
    "# Import src.datautils\n",
    "    \n",
    "from src import datautils\n",
    "\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "#             CONSTANTS             #\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "window_size = 40\n",
    "lead_time = 18\n",
    "\n",
    "# Normalisation:\n",
    "# ENERGY :\n",
    "shift_ = 18000.0 # e.g. mean , lookup from stats, you can round it up\n",
    "scale_ = 40000.0 # e.g. 2xS.D., lookup from stats\n",
    "# x_norm = (x-shift_)/scale_\n",
    "\n",
    "# WIND SPEED:\n",
    "wind_scale_ = 8.0 # half of max speed (wind vector)\n",
    "\n",
    "# location of networks\n",
    "model_dir = os.path.relpath('./best_models')\n",
    "# get all models that match the pattern:\n",
    "model_filenames = glob.glob(os.path.join(model_dir,'20Jul2020_1155_ver*'))\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "#        HELPER FUNCTIONS           #\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "# my server's offset time:\n",
    "time_offset = pd.Timedelta(minutes=6,seconds=-9) # correction to cpu time\n",
    "if TESTING:\n",
    "    time_offset = pd.Timedelta(hours=10,minutes=6,seconds=-9)\n",
    "\n",
    "def utc_now(time_delta = time_offset):\n",
    "    t = datetime.datetime.utcnow()\n",
    "    utc_time = pd.to_datetime('{}-{:02d}-{:02d} {:02d}:{:02d}:{:02d}'.format(\n",
    "        t.year,t.month,t.day, t.hour,t.minute,t.second))+time_delta\n",
    "    return utc_time\n",
    "\n",
    "def need_time():\n",
    "    '''Current time needed for Energy kWh readings'''\n",
    "    curr_time_utc = utc_now()\n",
    "    curr_minutes = curr_time_utc.minute\n",
    "    \n",
    "    if (curr_minutes<10) or (curr_minutes>29):\n",
    "        return curr_time_utc.round('H')-pd.Timedelta(hours=1)\n",
    "    return curr_time_utc.round('H')\n",
    "\n",
    "\n",
    "def send_value2url(val):\n",
    "    html=b''\n",
    "    passwrd = '961993551'\n",
    "    url_add = f'http://3.1.52.222/submit/pred?pwd={passwrd}&value={val}'\n",
    "    try:\n",
    "        with urllib.request.urlopen(url_add) as response:\n",
    "            html = response.read()\n",
    "    except urllib.request.HTTPError:\n",
    "        html = b'server is down'\n",
    "        print(utc_now(),f' (for {need_time()}):',html.decode(),url_add)\n",
    "    return html\n",
    "\n",
    "\n",
    "def read_wind_forecasts_w_range(wind_speed_range):\n",
    "    dfs = []\n",
    "    for model_n in range(1,3,1):\n",
    "        for farm_k in range(len(datautils.locations)):\n",
    "            dfs.append(\n",
    "                datautils.readlocation_as_vec( model_n,farm_k, wind_speed_range).interpolate(\n",
    "                    method='linear').reindex(wind_speed_range) )\n",
    "    # concatenate along axis 1 using datetime as reference\n",
    "    # then take average of two forecasts\n",
    "    return datautils.average_forecast_models( pd.concat(dfs,axis=1) )\n",
    "\n",
    "\n",
    "modellist = []\n",
    "for fname in model_filenames:\n",
    "    with open(fname, 'rb') as f:\n",
    "        print(f'Loading {fname}')\n",
    "        modellist.append(pickle.load(f))\n",
    "\n",
    "for net in modellist:\n",
    "    net.to(device)\n",
    "\n",
    "def predictT18(x,y_0,nets=modellist):\n",
    "    results = []\n",
    "    y_0 = torch.from_numpy(y_0.astype(np.float32)).to(device)\n",
    "    x = torch.from_numpy(x.astype(np.float32)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for net in modellist:\n",
    "            net.eval()\n",
    "            results.append(net(x,y_0).detach().cpu().numpy())\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def iter_predict18(energy_df, latest_energy_time_):\n",
    "    tau_fill = pd.date_range(latest_energy_time_+pd.Timedelta(hours=1), need_time(), freq='H')\n",
    "    \n",
    "    if tau_fill.shape[0]>39:\n",
    "        # if missing more than 39 hours just return 0\n",
    "        print(f'\\nToo many missing values for energy (missing {tau_fill.shape[0]} recent samples.)\\n')\n",
    "        return 0\n",
    "    # time range for Energy\n",
    "    eng_fill_range = pd.date_range(\n",
    "        tau_fill[0] - pd.Timedelta(hours=window_size-1+18), energy_df.index[-1], freq='H')\n",
    "    # normalised energy (copy)\n",
    "    eng_df_norm = ( energy_df.loc[eng_fill_range].copy(deep=True)- shift_)/scale_\n",
    "    \n",
    "    # time range for wind speed\n",
    "    wind_speed_range = pd.date_range(eng_fill_range[0],\n",
    "                                     need_time()+pd.Timedelta(hours=18),freq='H')\n",
    "    wind_df_norm = read_wind_forecasts_w_range(wind_speed_range)/wind_scale_\n",
    "    \n",
    "    # fill in missing values\n",
    "    for t in tau_fill:\n",
    "        need_range = pd.date_range(t-pd.Timedelta(hours=window_size-1+18),\n",
    "                                   t-pd.Timedelta(hours=18),freq='H')\n",
    "        Y_fill = eng_df_norm.loc[need_range].values.reshape(1,-1)\n",
    "        Y0_fill = Y_fill[:,:1]\n",
    "        Ydiff_fill = Y_fill[:,0:-1] - Y_fill[:,1:]\n",
    "        # wind needs T+18 forecast\n",
    "        need_range_wind = pd.date_range(need_range[0],\n",
    "                                        need_range[-1]+pd.Timedelta(hours=18),freq='H')\n",
    "        \n",
    "        X_df = wind_df_norm.loc[need_range_wind].values\n",
    "        X_norm = np.sqrt(X_df[:,0::2]**2 + X_df[:,1::2]**2)# wind speed from wind vectors\n",
    "        X_windows = []\n",
    "        for l in range(X_norm.shape[1]):\n",
    "            X_windows.append(\n",
    "                datautils.windowed_diff_data(X_norm[:,l], lead_time=lead_time, window_size=window_size))\n",
    "        \n",
    "        X_fill = [Ydiff_fill]\n",
    "        X_fill.extend(X_windows)\n",
    "        X_fill = np.concatenate(X_fill, axis=1)\n",
    "        eng_df_norm.loc[t] = np.mean(predictT18(X_fill,Y0_fill))\n",
    "    \n",
    "    # Predict T+18\n",
    "    # Y(T+0) and diff-s\n",
    "    need_range = pd.date_range(tau_fill[-1]-pd.Timedelta(hours=window_size-1),tau_fill[-1],freq='H')\n",
    "    Y = eng_df_norm.loc[need_range].values.reshape(1,-1)\n",
    "    Y0 = Y[:,:1]\n",
    "    Ydiff = Y[:,0:-1] - Y[:,1:]\n",
    "    \n",
    "    # X(T+18), X(T+0), and diff-s \n",
    "    # wind needs T+18 forecast\n",
    "    need_range_wind = pd.date_range(need_range[0], need_range[-1]+pd.Timedelta(hours=18),freq='H')\n",
    "    X_df = wind_df_norm.loc[need_range_wind].values\n",
    "    X_norm = np.sqrt(X_df[:,0::2]**2 + X_df[:,1::2]**2)# wind speed from wind vectors\n",
    "    X_windows = []\n",
    "    for l in range(X_norm.shape[1]):\n",
    "        X_windows.append(\n",
    "            datautils.windowed_diff_data(X_norm[:,l], lead_time=lead_time, window_size=window_size))\n",
    "    \n",
    "    Xdeploy = [Ydiff]\n",
    "    Xdeploy.extend(X_windows)\n",
    "    Xdeploy = np.concatenate(Xdeploy, axis=1)\n",
    "    \n",
    "    # Predict using 5 best models, and de-normalise, take mean for all predictions:\n",
    "    Y_pred = np.mean(np.array(predictT18(Xdeploy,Y0))*scale_ +shift_)\n",
    "    # Set 0kWh as min prediction, and convert to integer\n",
    "    Y_pred = np.maximum(0,int(Y_pred))\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - \n",
      "Deployment >  ON  <\n",
      "- - - - - - - - - - \n",
      "\n",
      "Latest wind forecasts:\n",
      "Downloaded latest forecasts from\n",
      "`https://ai4impact.org/P003/`\n",
      "saved to\n",
      "datasets\n",
      "\n",
      "Historical wind forecasts:\n",
      "Downloaded historical forecasts from\n",
      "`https://ai4impact.org/P003/historical/`\n",
      "saved to\n",
      "datasets\n",
      "\n",
      "Downloaded from:\n",
      "`https://ai4impact.org/P003/historical/energy-ile-de-france.csv`\n",
      "saved to:\n",
      "datasets/energy-ile-de-france.csv\n",
      "Downloading\n",
      "\"eCO2mix_RTE_Ile-de-France_En-cours-TR.zip\" from\n",
      "`https://eco2mix.rte-france.com/download/eco2mix/eCO2mix_RTE_Ile-de-France_En-cours-TR.zip`\n",
      "\n",
      "Extracting: datasets/eCO2mix_RTE_Ile-de-France_En-cours-TR.zip\n",
      "eCO2mix_RTE_Ile-de-France_En-cours-TR.xls --> as \"datasets/eCO2mix_RTE_Ile-de-France_En-cours-TR.xls\"\n",
      "- - - - - \n",
      "File Name                                             Modified             Size\n",
      "eCO2mix_RTE_Ile-de-France_En-cours-TR.xls      2020-07-20 16:31:34      1094308\n",
      "- - - - - \n",
      "Deleting\n",
      "datasets/eCO2mix_RTE_Ile-de-France_En-cours-TR.zip\n",
      "\n",
      "---\n",
      "Time elapsed: 0 days 00:00:06\n",
      "---\n",
      "\n",
      "\n",
      "Using iterative method: latest 2020-07-20 14:00:00 (need 2020-07-20 15:00:00)\n",
      "\n",
      "Submission time closed \n",
      "\n",
      "---\n",
      " 2020-07-20 15:12:33: Time elapsed: 0 days 00:00:13\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "print('\\n'+'- - '*5+\n",
    "      f'\\nDeployment > {\"Testing\" if TESTING else \" ON  <\"}\\n'+\n",
    "      '- - '*5+'\\n')\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # DEPLOYMENT LOOP # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "t0 = utc_now()\n",
    "# Download New Forecasts:\n",
    "datautils.download_forecasts_all()\n",
    "\n",
    "# AI4Impact source:\n",
    "datautils.download_energy_latest()\n",
    "energy_1 = datautils.read_ai4impact_energy('datasets/energy-ile-de-france.csv')\n",
    "\n",
    "# RTE source:\n",
    "RTE_file_path = datautils.download_raw_from_RTE('real_time',return_filelist=True)\n",
    "energy_2=datautils.read_RTE_as_kwh(RTE_file_path[0],convert2UTC=True)\n",
    "\n",
    "print(f'---\\nTime elapsed: {utc_now()-t0}\\n---\\n')\n",
    "\n",
    "# Select latest energy source\n",
    "enrg_src = np.argmax([energy_1.index[-1], energy_2.index[-1]])\n",
    "energy_df  = energy_1 if enrg_src==0 else energy_2\n",
    "energy_date_range = pd.date_range(energy_df.index[0],energy_df.index[-1],freq='H')\n",
    "\n",
    "\n",
    "need_range = pd.date_range(need_time()-pd.Timedelta(hours=window_size-1),need_time(),freq='H')\n",
    "\n",
    "\n",
    "if energy_df[energy_df.index==need_time()].values.shape[0]==0:\n",
    "    print(f'\\nUsing iterative method: latest {energy_date_range[-1]} (need {need_time()})\\n')\n",
    "    Y_pred = iter_predict18(energy_df, energy_date_range[-1])\n",
    "else:\n",
    "    print(f'\\nComputing T+18 forecast directly (latest {energy_date_range[-1]}, need {need_time()})\\n')\n",
    "    # we need this range of dates for features\n",
    "    oldest_time = need_time()-pd.Timedelta(hours=window_size-1)\n",
    "    wind_speed_latest_time = need_time()+pd.Timedelta(hours=18)\n",
    "    wind_speed_range = pd.date_range(oldest_time,wind_speed_latest_time,freq='H')\n",
    "\n",
    "    wind_df = read_wind_forecasts_w_range(wind_speed_range)\n",
    "\n",
    "    wind_norm = wind_df.values/wind_scale_\n",
    "    wind_speeds = np.sqrt(wind_norm[:,0::2]**2 + wind_norm[:,1::2]**2)# wind speed from wind vectors\n",
    "\n",
    "    X_norm_diffwindows = []\n",
    "    for l in range(wind_speeds.shape[1]):\n",
    "        X_norm_diffwindows.append(\n",
    "            datautils.windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size))\n",
    "    # print for debugging\n",
    "    # print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "    #       [l.shape for l in X_norm_diffwindows])\n",
    "    Y = (energy_df.loc[need_range].values[::-1,0].reshape(1,-1) - shift_)/scale_\n",
    "    Y0 = Y[:,:1]\n",
    "    Ydiff = Y[:,0:-1] - Y[:,1:]\n",
    "    Xdeploy = [Ydiff]\n",
    "    Xdeploy.extend(X_norm_diffwindows)\n",
    "    Xdeploy = np.concatenate(Xdeploy, axis=1)\n",
    "    # Predict using 5 best models, and de-normalise, take mean for all predictions:\n",
    "    Y_pred = np.mean(np.array(predictT18(Xdeploy,Y0))*scale_ +shift_)\n",
    "    # Set 0kWh as min prediction, and convert to integer\n",
    "    Y_pred = np.maximum(0,int(Y_pred))\n",
    "\n",
    "url_response = send_value2url(Y_pred)\n",
    "print(url_response.decode())\n",
    "print(f'---\\n {utc_now()}: Time elapsed: {utc_now()-t0}\\n---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_utc_time = utc_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Jul 20 15:28:30 2020'"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_utc_time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (curr_utc_time.minute+<50) and (curr_utc_time.minute>50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_left = curr_utc_time.minute - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while deployment_end_time>utc_now:\n",
    "    # sleep until 50min\n",
    "    curr_utc_time = utc_now()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-07-20 15:02:07.026366')"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to minutes/hours/ etc.:\n",
    "# pd.to_datetime('now').round('min')\n",
    "# extract current hour/minute/second/:\n",
    "# pd.to_datetime('now').second\n",
    "# ---\n",
    "# PAUSE EXAMPLE:\n",
    "# Do sth everyday at 2AM:\n",
    "# \n",
    "# import datetime\n",
    "\n",
    "# # if for some reason this script is still running\n",
    "# # after a year, we'll stop after 365 days\n",
    "# for i in xrange(0,365):\n",
    "#     # sleep until 2AM\n",
    "#     t = datetime.datetime.today()\n",
    "#     future = datetime.datetime(t.year,t.month,t.day,2,0)\n",
    "#     if t.hour >= 2:\n",
    "#         future += datetime.timedelta(days=1)\n",
    "#     time.sleep((future-t).seconds) # or use total_seconds() if the duration is longer than one day\n",
    "\n",
    "#     # do 2AM stuff\n",
    "\n",
    "# CURRENT TIME:\n",
    "# import time\n",
    "# import datetime\n",
    "# t = datetime.datetime.today()\n",
    "# print('Current time:\\n{}/{}/{} {}:{}:{}'.format(t.day,t.month,t.year, t.hour,t.minute,t.second))\n",
    "# t = datetime.datetime.utcnow()\n",
    "# print('UTC time:\\n{}/{}/{} {}:{}:{}'.format(t.day,t.month,t.year, t.hour,t.minute,t.second))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
