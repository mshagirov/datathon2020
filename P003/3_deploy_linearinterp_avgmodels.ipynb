{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "> run this notebook during deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check time offset correction use [https://www.utctime.net](https://www.utctime.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data from the RTE website collected from 0300 - 0400 Z is averaged and attributed to the time 0300Z. So when you submit a forecast between 0350-0410 Z , it is really meant for a T+0 = 0300Z. Finally, 0300Z + 18 hours = 2100Z as given in the response.\n",
    "\n",
    "USE `Energy[t-1, t-2,...]`, and `Forecast[t+17]` , i.e. `Energy[t-1]` is current reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our password is` 961993551 `\n",
    "```python\n",
    "Y_t18_prediction = 3500\n",
    "url_to_submit = f'http://3.1.52.222/submit/pred?pwd=961993551&value={Y_t18_prediction}'\n",
    "\n",
    "with urllib.request.urlopen(url_to_submit) as response:\n",
    "   html_valid = response.read()\n",
    "```\n",
    "then convert to pyhton str\n",
    "```python\n",
    "str(html_valid.decode())\n",
    "```\n",
    "if valid submission, we will receive:\n",
    "```\n",
    "> 'Submitted \\nReceived: 20-Jul-2020 04:02:50 UTC \\nFor     : 20-Jul-2020 21:00:00 UTC \\nValue   : 3500 \\n'\n",
    "```\n",
    "and for wrong timing/passwords:\n",
    "```\n",
    "if password is wrong:\n",
    "> 'Password invalid \\n'\n",
    "if submission is too early or late:\n",
    "> 'Submission time closed \\n'\n",
    "```\n",
    "\n",
    "an example for wrong submission code\n",
    "```python\n",
    "html=b''\n",
    "try:\n",
    "    with urllib.request.urlopen('http://3.1.52.222/submit/pred?pwd=961993551&value=3500') as response:\n",
    "        html = response.read()\n",
    "except urllib.request.HTTPError:\n",
    "    html = b'server down'\n",
    "\n",
    "print(html.decode())\n",
    "```\n",
    "\n",
    "`> server down`<br>\n",
    "or<br>\n",
    "```python\n",
    "html.decode().split('\\n')\n",
    "```\n",
    "`> ['Password invalid ', '']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Available device: cuda\n",
      "Loading best_models/20Jul2020_1155_ver2.pkl\n",
      "Loading best_models/20Jul2020_1155_ver1.pkl\n",
      "Loading best_models/20Jul2020_1155_ver5.pkl\n",
      "Loading best_models/20Jul2020_1155_ver3.pkl\n",
      "Loading best_models/20Jul2020_1155_ver4.pkl\n"
     ]
    }
   ],
   "source": [
    "# # Set to FALSE when deploying!!! # #\n",
    "TESTING = True\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob, pickle\n",
    "import urllib.request\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "#     device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Available device: {device}')\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "import datetime\n",
    "\n",
    "#For running in JupyterHub:\n",
    "if os.path.basename(os.getcwd())!='P003':\n",
    "    print('Not in /P003 folder, changing directory to P003')\n",
    "    lib_path = os.path.expanduser(os.path.relpath('~/images/codesDIR/datathon2020/P003'))\n",
    "    os.chdir(lib_path)\n",
    "\n",
    "# Import src.datautils\n",
    "    \n",
    "from src import datautils\n",
    "\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# my servers offset time:\n",
    "time_offset = pd.Timedelta(minutes=6,seconds=-9) # correction to cpu time\n",
    "if TESTING:\n",
    "    time_offset = pd.Timedelta(hours=10,minutes=6,seconds=-9)\n",
    "\n",
    "def utc_now(time_delta = time_offset):\n",
    "    t = datetime.datetime.utcnow()\n",
    "    utc_time = pd.to_datetime('{}-{:02d}-{:02d} {:02d}:{:02d}:{:02d}'.format(\n",
    "        t.year,t.month,t.day, t.hour,t.minute,t.second))+time_delta\n",
    "    return utc_time\n",
    "\n",
    "def need_time():\n",
    "    '''Current time needed for Energy kWh readings'''\n",
    "    curr_time_utc = utc_now()\n",
    "    curr_minutes = curr_time_utc.minute\n",
    "    \n",
    "    if (curr_minutes<10) or (curr_minutes>29):\n",
    "        return curr_time_utc.round('H')-pd.Timedelta(hours=1)\n",
    "    return curr_time_utc.round('H')\n",
    "\n",
    "\n",
    "def send_value2url(val):\n",
    "    html=b''\n",
    "    passwrd = '961993551'\n",
    "    url_add = f'http://3.1.52.222/submit/pred?pwd={passwrd}&value={val}'\n",
    "    try:\n",
    "        with urllib.request.urlopen(url_add) as response:\n",
    "            html = response.read()\n",
    "    except urllib.request.HTTPError:\n",
    "        html = b'server is down'\n",
    "        print(utc_now(),f' (for {need_time()}):',html.decode(),url_add)\n",
    "    return html\n",
    "\n",
    "\n",
    "def read_wind_forecasts_w_range(wind_speed_range):\n",
    "    dfs = []\n",
    "    for model_n in range(1,3,1):\n",
    "        for farm_k in range(len(datautils.locations)):\n",
    "            dfs.append(\n",
    "                datautils.readlocation_as_vec( model_n,farm_k, wind_speed_range).interpolate(\n",
    "                    method='linear').reindex(wind_speed_range) )\n",
    "    # concatenate along axis 1 using datetime as reference\n",
    "    # then take average of two forecasts\n",
    "    return datautils.average_forecast_models( pd.concat(dfs,axis=1) )\n",
    "\n",
    "\n",
    "# CONSTANTS:\n",
    "window_size = 40\n",
    "lead_time = 18\n",
    "\n",
    "# Normalisation:\n",
    "# ENERGY :\n",
    "shift_ = 18000.0 # e.g. mean , lookup from stats, you can round it up\n",
    "scale_ = 40000.0 # e.g. 2xS.D., lookup from stats\n",
    "# x_norm = (x-shift_)/scale_\n",
    "\n",
    "# WIND SPEED:\n",
    "wind_scale_ = 8.0 # half of max speed (wind vector)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# location of networks\n",
    "model_dir = os.path.relpath('./best_models')\n",
    "# get all models that match the pattern:\n",
    "model_filenames = glob.glob(os.path.join(model_dir,'20Jul2020_1155_ver*'))\n",
    "\n",
    "modellist = []\n",
    "for fname in model_filenames:\n",
    "    with open(fname, 'rb') as f:\n",
    "        print(f'Loading {fname}')\n",
    "        modellist.append(pickle.load(f))\n",
    "\n",
    "for net in modellist:\n",
    "    net.to(device)\n",
    "\n",
    "def predictT18(x,y_0,nets=modellist):\n",
    "    results = []\n",
    "    y_0 = torch.from_numpy(y_0.astype(np.float32)).to(device)\n",
    "    x = torch.from_numpy(x.astype(np.float32)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for net in modellist:\n",
    "            net.eval()\n",
    "            results.append(net(x,y_0).detach().cpu().numpy())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - \n",
      "Deployment >Testing\n",
      "- - - - - - - - - - \n",
      "\n",
      "Latest wind forecasts:\n",
      "Downloaded latest forecasts from\n",
      "`https://ai4impact.org/P003/`\n",
      "saved to\n",
      "datasets\n",
      "\n",
      "Historical wind forecasts:\n",
      "Downloaded historical forecasts from\n",
      "`https://ai4impact.org/P003/historical/`\n",
      "saved to\n",
      "datasets\n",
      "\n",
      "---\n",
      "Time elapsed: 0 days 00:00:10\n",
      "---\n",
      "\n",
      "Downloaded from:\n",
      "`https://ai4impact.org/P003/historical/energy-ile-de-france.csv`\n",
      "saved to:\n",
      "datasets/energy-ile-de-france.csv\n",
      "Downloading\n",
      "\"eCO2mix_RTE_Ile-de-France_En-cours-TR.zip\" from\n",
      "`https://eco2mix.rte-france.com/download/eco2mix/eCO2mix_RTE_Ile-de-France_En-cours-TR.zip`\n",
      "\n",
      "Extracting: datasets/eCO2mix_RTE_Ile-de-France_En-cours-TR.zip\n",
      "eCO2mix_RTE_Ile-de-France_En-cours-TR.xls --> as \"datasets/eCO2mix_RTE_Ile-de-France_En-cours-TR.xls\"\n",
      "- - - - - \n",
      "File Name                                             Modified             Size\n",
      "eCO2mix_RTE_Ile-de-France_En-cours-TR.xls      2020-07-20 13:31:20      1092858\n",
      "- - - - - \n",
      "Deleting\n",
      "datasets/eCO2mix_RTE_Ile-de-France_En-cours-TR.zip\n",
      "\n",
      "---\n",
      "Time elapsed: 0 days 00:00:03\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'+'- - '*5+'\\nDeployment >'+\n",
    "      f'{\"Testing\" if TESTING else \" ON  <\"}\\n'+\n",
    "      '- - '*5+'\\n')\n",
    "# Deployment loop:\n",
    "\n",
    "t0 = utc_now()\n",
    "# Download New Forecasts:\n",
    "datautils.download_forecasts_all()\n",
    "\n",
    "# we need this range of dates for features\n",
    "oldest_time = need_time()-pd.Timedelta(hours=window_size-1)\n",
    "wind_speed_latest_time = need_time()+pd.Timedelta(hours=18)\n",
    "wind_speed_range = pd.date_range(oldest_time,wind_speed_latest_time,freq='H')\n",
    "\n",
    "wind_df = read_wind_forecasts_w_range(wind_speed_range)\n",
    "print(f'---\\nTime elapsed: {utc_now()-t0}\\n---\\n')\n",
    "\n",
    "wind_norm = wind_df.values/wind_scale_\n",
    "wind_speeds = np.sqrt(wind_norm[:,0::2]**2 + wind_norm[:,1::2]**2)# wind speed from wind vectors\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        datautils.windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size))\n",
    "# print for debugging\n",
    "# print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "#       [l.shape for l in X_norm_diffwindows])\n",
    "\n",
    "t0 = utc_now()\n",
    "# AI4Impact source:\n",
    "datautils.download_energy_latest()\n",
    "energy_1 = datautils.read_ai4impact_energy('datasets/energy-ile-de-france.csv')\n",
    "\n",
    "# RTE source:\n",
    "RTE_file_path = datautils.download_raw_from_RTE('real_time',return_filelist=True)\n",
    "energy_2=datautils.read_RTE_as_kwh(RTE_file_path[0],convert2UTC=True)\n",
    "\n",
    "print(f'---\\nTime elapsed: {utc_now()-t0}\\n---\\n')\n",
    "\n",
    "# Select latest energy source\n",
    "enrg_src = np.argmax([energy_1.index[-1], energy_2.index[-1]])\n",
    "energy_df  = energy_1 if enrg_src==0 else energy_2\n",
    "energy_date_range = pd.date_range(energy_df.index[0],energy_df.index[-1],freq='H')\n",
    "\n",
    "\n",
    "need_range = pd.date_range(need_time()-pd.Timedelta(hours=window_size-1),need_time(),freq='H')\n",
    "\n",
    "\n",
    "if energy_df[energy_df.index==need_time()].values.shape[0]==0:\n",
    "    Y0=None\n",
    "    Y=None\n",
    "else:\n",
    "    Y = (energy_df.loc[need_range].values[::-1,0].reshape(1,-1) - shift_)/scale_\n",
    "    Y0 = Y[:,:1]\n",
    "    Ydiff = Y[:,0:-1] - Y[:,1:]\n",
    "    Xdeploy = [Ydiff]\n",
    "    Xdeploy.extend(X_norm_diffwindows)\n",
    "    Xdeploy = np.concatenate(Xdeploy, axis=1)\n",
    "    # Predict using 5 best models, and de-normalise, take mean for all predictions:\n",
    "    Y_pred = np.mean(np.array(predictT18(Xdeploy,Y0))*scale_ +shift_)\n",
    "    # Set 0kWh as min prediction, and convert to integer\n",
    "    Y_pred = np.maximum(0,int(Y_pred))\n",
    "    url_response = send_value2url(Y_pred)\n",
    "    print(url_response.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_range = None\n",
    "fill_range = None # need samples from this range to fill in missing range\n",
    "if Y0==None:\n",
    "    missing_range = pd.date_range(energy_date_range[-1]+pd.Timedelta(hours=1),need_time(),freq='H')\n",
    "    fill_range = missing_range - pd.Timedelta(hours=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-07-20 12:00:00', '2020-07-20 13:00:00',\n",
      "               '2020-07-20 14:00:00', '2020-07-20 15:00:00',\n",
      "               '2020-07-20 16:00:00', '2020-07-20 17:00:00',\n",
      "               '2020-07-20 18:00:00', '2020-07-20 19:00:00',\n",
      "               '2020-07-20 20:00:00', '2020-07-20 21:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H') \n",
      " DatetimeIndex(['2020-07-19 18:00:00', '2020-07-19 19:00:00',\n",
      "               '2020-07-19 20:00:00', '2020-07-19 21:00:00',\n",
      "               '2020-07-19 22:00:00', '2020-07-19 23:00:00',\n",
      "               '2020-07-20 00:00:00', '2020-07-20 01:00:00',\n",
      "               '2020-07-20 02:00:00', '2020-07-20 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n"
     ]
    }
   ],
   "source": [
    "print(missing_range, '\\n',fill_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need this range of dates for features\n",
    "oldest_time = need_time()-pd.Timedelta(hours=window_size-1)\n",
    "wind_speed_latest_time = need_time()+pd.Timedelta(hours=18)\n",
    "wind_speed_range = pd.date_range(oldest_time,wind_speed_latest_time,freq='H')\n",
    "\n",
    "wind_df = read_wind_forecasts_w_range(wind_speed_range)\n",
    "print(f'---\\nTime elapsed: {utc_now()-t0}\\n---\\n')\n",
    "\n",
    "wind_norm = wind_df.values/wind_scale_\n",
    "wind_speeds = np.sqrt(wind_norm[:,0::2]**2 + wind_norm[:,1::2]**2)# wind speed from wind vectors\n",
    "\n",
    "X_norm_diffwindows = []\n",
    "for l in range(wind_speeds.shape[1]):\n",
    "    X_norm_diffwindows.append(\n",
    "        datautils.windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised data\n",
    "Yt = data_norm[:,0].reshape(-1,1)\n",
    "\n",
    "start_time = window_size-1 # index of last elem of window\n",
    "\n",
    "# Y(t)\n",
    "# prepare windows : 1st columns Y(T+lead_time)\n",
    "Y_norm_diffwind = windowed_diff_data(Yt, lead_time=lead_time, window_size=window_size)\n",
    "print(f'\\nFull Diff windowed dataset (1st column is target Y(T+{lead_time}): {Y_norm_diffwind.shape}',\n",
    "      f\"; windowsize:{window_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
