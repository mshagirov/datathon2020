{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Deployment\n",
    "> run this notebook during deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To check time offset correction use [https://www.utctime.net](https://www.utctime.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Data from the RTE website collected from 0300 - 0400 Z is averaged and attributed to the time 0300Z. So when you submit a forecast between 0350-0410 Z , it is really meant for a T+0 = 0300Z. Finally, 0300Z + 18 hours = 2100Z as given in the response.\n",
    "\n",
    "USE `Energy[t-1, t-2,...]`, and `Forecast[t+17]` , i.e. `Energy[t-1]` is current reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "our password is` 961993551 `\n",
    "```python\n",
    "Y_t18_prediction = 3500\n",
    "url_to_submit = f'http://3.1.52.222/submit/pred?pwd=961993551&value={Y_t18_prediction}'\n",
    "\n",
    "with urllib.request.urlopen(url_to_submit) as response:\n",
    "   html_valid = response.read()\n",
    "```\n",
    "then convert to pyhton str\n",
    "```python\n",
    "str(html_valid.decode())\n",
    "```\n",
    "if valid submission, we will receive:\n",
    "```\n",
    "> 'Submitted \\nReceived: 20-Jul-2020 04:02:50 UTC \\nFor     : 20-Jul-2020 21:00:00 UTC \\nValue   : 3500 \\n'\n",
    "```\n",
    "and for wrong timing/passwords:\n",
    "```\n",
    "if password is wrong:\n",
    "> 'Password invalid \\n'\n",
    "if submission is too early or late:\n",
    "> 'Submission time closed \\n'\n",
    "```\n",
    "\n",
    "an example for wrong submission code\n",
    "```python\n",
    "html=b''\n",
    "try:\n",
    "    with urllib.request.urlopen('http://3.1.52.222/submit/pred?pwd=961993551&value=3500') as response:\n",
    "        html = response.read()\n",
    "except urllib.request.HTTPError:\n",
    "    html = b'server down'\n",
    "\n",
    "print(html.decode())\n",
    "```\n",
    "\n",
    "`> server down`<br>\n",
    "or<br>\n",
    "```python\n",
    "html.decode().split('\\n')\n",
    "```\n",
    "`> ['Password invalid ', '']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T19:48:58.948664Z",
     "start_time": "2020-07-23T19:48:58.855351Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cuda:3\n",
      "Loading best_models/24Jul2020_0150_ver5.pkl\n",
      "Loading best_models/24Jul2020_0150_ver4.pkl\n",
      "Loading best_models/24Jul2020_0150_ver2.pkl\n",
      "Loading best_models/24Jul2020_0150_ver1.pkl\n",
      "Loading best_models/24Jul2020_0150_ver3.pkl\n"
     ]
    }
   ],
   "source": [
    "# # Set to FALSE when deploying!!! # #\n",
    "TESTING = False\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "import os, glob, pickle\n",
    "import urllib.request\n",
    "import torch, numpy as np\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "import time, datetime\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Available device: {device}')\n",
    "\n",
    "\n",
    "#For running in JupyterHub:\n",
    "if os.path.basename(os.getcwd())!='P003':\n",
    "    print('Not in /P003 folder, changing directory to P003')\n",
    "    lib_path = os.path.expanduser(os.path.relpath('~/images/codesDIR/datathon2020/P003'))\n",
    "    os.chdir(lib_path)\n",
    "\n",
    "# Import src.datautils\n",
    "    \n",
    "from src import datautils\n",
    "\n",
    "# import matplotlib\n",
    "#plt.style.use('ggplot')\n",
    "#%matplotlib inline\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "#             CONSTANTS             #\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "window_size = 40\n",
    "lead_time = 18\n",
    "\n",
    "# Normalisation:\n",
    "# ENERGY :\n",
    "shift_ = 18000.0 # e.g. mean , lookup from stats, you can round it up\n",
    "scale_ = 40000.0 # e.g. 2xS.D., lookup from stats\n",
    "# x_norm = (x-shift_)/scale_\n",
    "\n",
    "# WIND SPEED:\n",
    "wind_scale_ = 8.0 # half of max speed (wind vector)\n",
    "\n",
    "# location of networks\n",
    "model_dir = os.path.relpath('./best_models')\n",
    "# get all models that match the pattern:\n",
    "model_filenames = glob.glob(os.path.join(model_dir,'24Jul2020_*'))\n",
    "\n",
    "# Just in case\n",
    "deployment_end_time  = pd.to_datetime('2020-12-29 10:00:00')\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "#        HELPER FUNCTIONS           #\n",
    "# # # # # # # # # # # # # # # # # # #\n",
    "# my server's offset time:\n",
    "time_offset = pd.Timedelta(minutes=0,seconds=0) # correction to cpu time\n",
    "# jhub offset--> pd.Timedelta(minutes=6,seconds=-9)\n",
    "if TESTING:\n",
    "    time_offset = pd.Timedelta(hours=10,minutes=0,seconds=0)\n",
    "\n",
    "def utc_now(time_delta = time_offset):\n",
    "    t = datetime.datetime.utcnow()\n",
    "    utc_time = pd.to_datetime('{}-{:02d}-{:02d} {:02d}:{:02d}:{:02d}'.format(\n",
    "        t.year,t.month,t.day, t.hour,t.minute,t.second))+time_delta\n",
    "    return utc_time\n",
    "\n",
    "def need_time():\n",
    "    '''Current time needed for Energy kWh readings'''\n",
    "    curr_time_utc = utc_now()\n",
    "    curr_minutes = curr_time_utc.minute\n",
    "    \n",
    "    if (curr_minutes<10) or (curr_minutes>29):\n",
    "        return curr_time_utc.round('H')-pd.Timedelta(hours=1)\n",
    "    return curr_time_utc.round('H')\n",
    "\n",
    "def sleep4time(curr_utc_time):\n",
    "    # sleep until 50min\n",
    "    min_now = curr_utc_time.minute + curr_utc_time.second/60\n",
    "    if (min_now<50) and (min_now>10):\n",
    "        # deploy time 1: wait for HH:51min\n",
    "        time_left = (50-min_now)*60 # in seconds\n",
    "    elif (min_now>=50):\n",
    "        # deploy time 2: wait for HH:00min\n",
    "        time_left = (60-min_now)*60 # in seconds\n",
    "    elif min_now<9:\n",
    "        #deploy time 3: wait for HH:09min\n",
    "        time_left = (9-min_now)*60 # in seconds\n",
    "    elif (min_now>9.5) and (min_now<50):\n",
    "        # deploy time 1: wait for HH:51min\n",
    "        time_left = (50-min_now)*60 # in seconds\n",
    "    if (curr_utc_time.minute==0) and (curr_utc_time.second<15):\n",
    "        time_left = 0.0\n",
    "    print(f'\\nSleep {time_left/60:2.0f}mins\\n')\n",
    "    time.sleep(abs(time_left))\n",
    "\n",
    "def send_value2url(val):\n",
    "    html=b''\n",
    "    passwrd = '961993551'\n",
    "    url_add = f'http://3.1.52.222/submit/pred?pwd={passwrd}&value={val}'\n",
    "    try:\n",
    "        with urllib.request.urlopen(url_add) as response:\n",
    "            html = response.read()\n",
    "    except urllib.request.HTTPError:\n",
    "        html = b'server is down'\n",
    "        print(utc_now(),f' (for {need_time()}):',html.decode(),url_add)\n",
    "    return html\n",
    "\n",
    "\n",
    "def read_wind_forecasts_w_range(wind_speed_range):\n",
    "    dfs = []\n",
    "    for model_n in range(1,3,1):\n",
    "        for farm_k in range(len(datautils.locations)):\n",
    "            dfs.append(\n",
    "                datautils.readlocation_as_vec( model_n,farm_k, wind_speed_range).interpolate(\n",
    "                    method='linear').reindex(wind_speed_range) )\n",
    "    # concatenate along axis 1 using datetime as reference\n",
    "    # then take average of two forecasts\n",
    "    return datautils.average_forecast_models( pd.concat(dfs,axis=1) )\n",
    "\n",
    "\n",
    "modellist = []\n",
    "for fname in model_filenames:\n",
    "    with open(fname, 'rb') as f:\n",
    "        print(f'Loading {fname}')\n",
    "        modellist.append(pickle.load(f))\n",
    "\n",
    "for net in modellist:\n",
    "    net.to(device)\n",
    "\n",
    "def predictT18(x,y_0,nets=modellist):\n",
    "    results = []\n",
    "    y_0 = torch.from_numpy(y_0.astype(np.float32)).to(device)\n",
    "    x = torch.from_numpy(x.astype(np.float32)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for net in modellist:\n",
    "            net.eval()\n",
    "            results.append(net(x,y_0).detach().cpu().numpy())\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def iter_predict18(energy_df, latest_energy_time_):\n",
    "    tau_fill = pd.date_range(latest_energy_time_+pd.Timedelta(hours=1), need_time(), freq='H')\n",
    "    \n",
    "    if tau_fill.shape[0]>39:\n",
    "        # if missing more than 39 hours just return 0\n",
    "        print(f'\\nToo many missing values for energy (missing {tau_fill.shape[0]} recent samples.)\\n')\n",
    "        return 0\n",
    "    # time range for Energy\n",
    "    eng_fill_range = pd.date_range(\n",
    "        tau_fill[0] - pd.Timedelta(hours=window_size-1+18), energy_df.index[-1], freq='H')\n",
    "    # normalised energy (copy)\n",
    "    eng_df_norm = ( energy_df.loc[eng_fill_range].copy(deep=True)- shift_)/scale_\n",
    "    \n",
    "    # time range for wind speed\n",
    "    wind_speed_range = pd.date_range(eng_fill_range[0],\n",
    "                                     need_time()+pd.Timedelta(hours=18),freq='H')\n",
    "    wind_df_norm = read_wind_forecasts_w_range(wind_speed_range)/wind_scale_\n",
    "    \n",
    "    X_clock = np.cos(np.pi*(tau_fill.hour.values)/23)**2\n",
    "    \n",
    "    # fill in missing values\n",
    "    for k, t in enumerate(tau_fill):\n",
    "        need_range = pd.date_range(t-pd.Timedelta(hours=window_size-1+18),\n",
    "                                   t-pd.Timedelta(hours=18),freq='H')\n",
    "        Y_fill = eng_df_norm.loc[need_range].values.reshape(1,-1)\n",
    "        Y0_fill = Y_fill[:,:1]\n",
    "        Ydiff_fill = Y_fill[:,0:-1] - Y_fill[:,1:]\n",
    "        # wind needs T+18 forecast\n",
    "        need_range_wind = pd.date_range(need_range[0],\n",
    "                                        need_range[-1]+pd.Timedelta(hours=18),freq='H')\n",
    "        \n",
    "        X_df = wind_df_norm.loc[need_range_wind].values\n",
    "        X_norm = np.sqrt(X_df[:,0::2]**2 + X_df[:,1::2]**2)# wind speed from wind vectors\n",
    "        X_windows = []\n",
    "        for l in range(X_norm.shape[1]):\n",
    "            X_windows.append(\n",
    "                datautils.windowed_diff_data(X_norm[:,l], lead_time=lead_time, window_size=window_size))\n",
    "        \n",
    "        X_fill = [Ydiff_fill]\n",
    "        X_fill.extend(X_windows)\n",
    "        X_fill.append(X_clock[k].reshape(1,1))\n",
    "        X_fill = np.concatenate(X_fill, axis=1)\n",
    "        eng_df_norm.loc[t] = np.mean(predictT18(X_fill,Y0_fill))\n",
    "    \n",
    "    # Predict T+18\n",
    "    # Y(T+0) and diff-s\n",
    "    need_range = pd.date_range(tau_fill[-1]-pd.Timedelta(hours=window_size-1),tau_fill[-1],freq='H')\n",
    "    Y = eng_df_norm.loc[need_range].values.reshape(1,-1)\n",
    "    Y0 = Y[:,:1]\n",
    "    Ydiff = Y[:,0:-1] - Y[:,1:]\n",
    "    \n",
    "    # X(T+18), X(T+0), and diff-s \n",
    "    # wind needs T+18 forecast\n",
    "    need_range_wind = pd.date_range(need_range[0], need_range[-1]+pd.Timedelta(hours=18),freq='H')\n",
    "    X_df = wind_df_norm.loc[need_range_wind].values\n",
    "    X_norm = np.sqrt(X_df[:,0::2]**2 + X_df[:,1::2]**2)# wind speed from wind vectors\n",
    "    \n",
    "    # Time of day T+18\n",
    "    X_clock = np.cos(np.pi*(need_time()+pd.Timedelta(hours=18)).hour/23)**2\n",
    "    X_clock = X_clock.reshape(-1,1)\n",
    "    \n",
    "    X_windows = []\n",
    "    for l in range(X_norm.shape[1]):\n",
    "        X_windows.append(\n",
    "            datautils.windowed_diff_data(X_norm[:,l], lead_time=lead_time, window_size=window_size))\n",
    "    \n",
    "    Xdeploy = [Ydiff]\n",
    "    Xdeploy.extend(X_windows)\n",
    "    Xdeploy.append(X_clock)\n",
    "    Xdeploy = np.concatenate(Xdeploy, axis=1)\n",
    "    \n",
    "    # Predict using 5 best models, and de-normalise, take mean for all predictions:\n",
    "    Y_pred = np.mean(np.array(predictT18(Xdeploy,Y0))*scale_ +shift_)\n",
    "    # Set 0kWh as min prediction, and convert to integer\n",
    "    Y_pred = np.maximum(0,int(Y_pred))\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T19:56:32.951432Z",
     "start_time": "2020-07-23T19:53:25.909350Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - \n",
      "Deployment >  ON  <\n",
      "- - - - - - - - - - \n",
      "\n",
      "\n",
      "Sleep  7mins\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-16340c08c7a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mdeployment_end_time\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mutc_now\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTESTING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msleep4time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutc_now\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutc_now\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Download New Forecasts:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-a6c2d68a52b9>\u001b[0m in \u001b[0;36msleep4time\u001b[0;34m(curr_utc_time)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nSleep {time_left/60:2.0f}mins\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend_value2url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "print('\\n'+'- - '*5+\n",
    "      f'\\nDeployment > {\"Testing\" if TESTING else \" ON  <\"}\\n'+\n",
    "      '- - '*5+'\\n')\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # DEPLOYMENT LOOP # # # # # # # # # # # # #\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "while deployment_end_time>utc_now():\n",
    "    if not TESTING:\n",
    "        sleep4time(utc_now())\n",
    "        t0 = utc_now()\n",
    "        # Download New Forecasts:\n",
    "        datautils.download_forecasts_all()\n",
    "        # AI4Impact source:\n",
    "        datautils.download_energy_latest()\n",
    "        print(f'---\\nTime elapsed: {utc_now()-t0}\\n---\\n')\n",
    "    \n",
    "    # energy readings\n",
    "    energy_df = datautils.read_ai4impact_energy('datasets/energy-ile-de-france.csv')\n",
    "    energy_date_range = pd.date_range(energy_df.index[0],energy_df.index[-1],freq='H') \n",
    "    \n",
    "    need_range = pd.date_range(need_time()-pd.Timedelta(hours=window_size-1),need_time(),freq='H')\n",
    "    \n",
    "    if energy_df[energy_df.index==need_time()].values.shape[0]==0:\n",
    "        print(f'\\nUsing iterative method: latest {energy_date_range[-1]} (need {need_time()})\\n')\n",
    "        Y_pred = iter_predict18(energy_df, energy_date_range[-1])\n",
    "        pred_method = f'iterative ({energy_date_range[-1]})'\n",
    "    else:\n",
    "        print(f'\\nComputing T+18 forecast directly (latest {energy_date_range[-1]}, need {need_time()})\\n')\n",
    "        # we need this range of dates for features\n",
    "        oldest_time = need_time()-pd.Timedelta(hours=window_size-1) # past data with window_size\n",
    "        wind_speed_latest_time = need_time()+pd.Timedelta(hours=18) # T+18 wind\n",
    "        wind_speed_range = pd.date_range(oldest_time,wind_speed_latest_time,freq='H') # select window_size and all the way to T+18\n",
    "        \n",
    "        wind_df = read_wind_forecasts_w_range(wind_speed_range)\n",
    "        wind_norm = wind_df.values/wind_scale_\n",
    "        wind_speeds = np.sqrt(wind_norm[:,0::2]**2 + wind_norm[:,1::2]**2)# wind speed from wind vectors\n",
    "        \n",
    "        # Time of day T+18\n",
    "        X_clock = np.cos(np.pi*(need_time()+pd.Timedelta(hours=18)).hour/23)**2\n",
    "        X_clock = X_clock.reshape(-1,1)\n",
    "        \n",
    "        X_norm_diffwindows = []\n",
    "        for l in range(wind_speeds.shape[1]):\n",
    "            X_norm_diffwindows.append(\n",
    "                datautils.windowed_diff_data(wind_speeds[:,l], lead_time=lead_time, window_size=window_size))\n",
    "        # print for debugging\n",
    "        # print('\\nX(t+18),X(T+0),X(T+0)-X(T-1),...,X(T-window_size+2)-X(T-window_size+1):\\n',\n",
    "        #       [l.shape for l in X_norm_diffwindows])\n",
    "        Y = (energy_df.loc[need_range].values[::-1,0].reshape(1,-1) - shift_)/scale_\n",
    "        Y0 = Y[:,:1]\n",
    "        Ydiff = Y[:,0:-1] - Y[:,1:]\n",
    "        Xdeploy = [Ydiff]\n",
    "        Xdeploy.extend(X_norm_diffwindows)\n",
    "        Xdeploy.append(X_clock)\n",
    "        Xdeploy = np.concatenate(Xdeploy, axis=1)\n",
    "        # Predict using 5 best models, and de-normalise, take mean for all predictions:\n",
    "        Y_pred = np.mean(np.array(predictT18(Xdeploy,Y0))*scale_ +shift_)\n",
    "        # Set 0kWh as min prediction, and convert to integer\n",
    "        Y_pred = np.maximum(0,int(Y_pred))\n",
    "        pred_method = f'direct ({energy_date_range[-1]})'\n",
    "        \n",
    "    curr_utc_time = utc_now()\n",
    "    curr_mins = curr_utc_time.minute +curr_utc_time.second/60\n",
    "    if (curr_mins<50) and (curr_mins>10):\n",
    "        continue\n",
    "    url_response = send_value2url(Y_pred)\n",
    "    print(url_response.decode())\n",
    "    with open('rt_predictions.txt', 'a') as the_file:\n",
    "        the_file.write(f'{utc_now()}: {Y_pred} (for {need_time()}, {pred_method}) {url_response.decode()}\\n')\n",
    "    print(f'---\\n {utc_now()}: Time elapsed: {utc_now()-t0}\\n---\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T19:57:33.259856Z",
     "start_time": "2020-07-23T19:57:32.917684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "murat    14113  0.0  0.0 131828  1240 pts/1    S+   03:49   0:00 screen -r my_deploy\r\n",
      "murat    14803  6.6  0.3 29290976 1601588 pts/6 Sl+ 03:56   0:04 python deploy_models_v2.py\r\n",
      "murat    14923  0.0  0.0 113196  1408 pts/8    Ss+  03:57   0:00 /usr/bin/sh -c ps -aux |grep deploy\r\n",
      "murat    14925  0.0  0.0 112700   756 pts/8    S+   03:57   0:00 grep deploy\r\n",
      "murat    23889  0.0  0.0 132124  1696 ?        Ss   Jul21   0:00 SCREEN -S my_deploy\r\n"
     ]
    }
   ],
   "source": [
    "!ps -aux |grep deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
